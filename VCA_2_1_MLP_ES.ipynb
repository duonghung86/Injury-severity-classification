{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/duonghung86/Injury-severity-classification/blob/main/VCA_2_1_MLP_earlystopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bo-3JT-1cl14",
    "outputId": "c710009f-72c5-44ef-9e68-7b27f7c8d34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 202.3 gigabytes of available RAM\n",
      "\n",
      "Current system-wide CPU utilization %:  32.9\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory,cpu_percent\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "print('Current system-wide CPU utilization %: ',cpu_percent())\n",
    "#Remove all warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ond2r97pZvoF",
    "outputId": "090a81b4-6b1f-46d8-abb5-725257820a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler # Standardization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Machine learning algos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Metrics\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import feature_column  # for data wrangling\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "#Remove all warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMFYXIMkFSak",
    "outputId": "d80430a7-b93b-421a-a2d9-3b1cbf3e5ba5"
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/duonghung86/Injury-severity-classification/blob/main/Prepared%20Texas%202019.zip?raw=true' \n",
    "data_path = tf.keras.utils.get_file(origin=url, fname=url.split('/')[-1].split('?')[0], extract=True)\n",
    "data_path = data_path.replace('%20',' ').replace('.zip','.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "UPLNCpWjZvoG",
    "outputId": "7d652183-53ce-4328-aada-ea393cc2efce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(949856, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prsn_Injry_Sev</th>\n",
       "      <th>Prsn_Age</th>\n",
       "      <th>Prsn_Gndr</th>\n",
       "      <th>Wthr_Cond</th>\n",
       "      <th>Light_Cond</th>\n",
       "      <th>Surf_Cond</th>\n",
       "      <th>Veh_Body_Styl</th>\n",
       "      <th>Prsn_Rest</th>\n",
       "      <th>Prsn_Drg_Rslt</th>\n",
       "      <th>Harm_Evnt</th>\n",
       "      <th>Rural</th>\n",
       "      <th>Crash_Speed_Limit</th>\n",
       "      <th>Road_Algn</th>\n",
       "      <th>Veh_Mod_Year</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Crash_season</th>\n",
       "      <th>Part_of_day</th>\n",
       "      <th>Collsn_type</th>\n",
       "      <th>Collsn_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>MALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PASSENGER CAR, 2-DOOR</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>STRAIGHT, LEVEL</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>ONE STRAIGHT-ONE LEFT TURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>MALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PASSENGER CAR, 2-DOOR</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>STRAIGHT, LEVEL</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>ONE STRAIGHT-ONE LEFT TURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PICKUP</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>CURVE, LEVEL</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>BOTH LEFT TURN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prsn_Injry_Sev  Prsn_Age Prsn_Gndr Wthr_Cond Light_Cond Surf_Cond  \\\n",
       "0               0        26      MALE     CLEAR   DAYLIGHT       DRY   \n",
       "1               0        52      MALE     CLEAR   DAYLIGHT       DRY   \n",
       "2               0        27    FEMALE     CLEAR   DAYLIGHT       DRY   \n",
       "\n",
       "           Veh_Body_Styl            Prsn_Rest   Prsn_Drg_Rslt  \\\n",
       "0  PASSENGER CAR, 2-DOOR  SHOULDER & LAP BELT  Not Applicable   \n",
       "1  PASSENGER CAR, 2-DOOR  SHOULDER & LAP BELT  Not Applicable   \n",
       "2                 PICKUP  SHOULDER & LAP BELT  Not Applicable   \n",
       "\n",
       "                    Harm_Evnt  Rural  Crash_Speed_Limit        Road_Algn  \\\n",
       "0  MOTOR VEHICLE IN TRANSPORT      0                 -1  STRAIGHT, LEVEL   \n",
       "1  MOTOR VEHICLE IN TRANSPORT      0                 -1  STRAIGHT, LEVEL   \n",
       "2  MOTOR VEHICLE IN TRANSPORT      1                 -1     CURVE, LEVEL   \n",
       "\n",
       "   Veh_Mod_Year  Weekend  Crash_season  Part_of_day     Collsn_type  \\\n",
       "0            33        1             3            3  SAME DIRECTION   \n",
       "1            19        1             3            3  SAME DIRECTION   \n",
       "2            16        1             3            4  SAME DIRECTION   \n",
       "\n",
       "                  Collsn_name  \n",
       "0  ONE STRAIGHT-ONE LEFT TURN  \n",
       "1  ONE STRAIGHT-ONE LEFT TURN  \n",
       "2              BOTH LEFT TURN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(data_path)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1CDPbDPYZvoH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47492, 19)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's just use 80% of the total dataset\n",
    "df, _ = train_test_split(df, test_size=0.9,stratify = df['Prsn_Injry_Sev'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEKbv3R9ZvoH",
    "outputId": "93f16610-1110-4ffe-9c66-f4dea88ae652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All target values:\n",
      "0    39627\n",
      "1     5120\n",
      "2     2262\n",
      "3      398\n",
      "4       85\n",
      "Name: Prsn_Injry_Sev, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df['Prsn_Injry_Sev']\n",
    "print('All target values:')\n",
    "print(y.value_counts())\n",
    "X = df.drop(columns=['Prsn_Injry_Sev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUDtEBDsZvoI",
    "outputId": "b311b931-acd8-453a-95f9-b54c0b572d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical variables are  ['Prsn_Age', 'Rural', 'Crash_Speed_Limit', 'Veh_Mod_Year', 'Weekend', 'Crash_season', 'Part_of_day']\n",
      "Categorical variables that have at most 5 categories are  ['Prsn_Gndr', 'Prsn_Drg_Rslt', 'Collsn_type']\n",
      "Categorical variables that have more than 5 categories are  ['Wthr_Cond', 'Light_Cond', 'Surf_Cond', 'Veh_Body_Styl', 'Prsn_Rest', 'Harm_Evnt', 'Road_Algn', 'Collsn_name']\n",
      "New shape of the input data set: (47492, 59)\n"
     ]
    }
   ],
   "source": [
    "# %% Data wrangling -------------\n",
    "# Classify variable type\n",
    "emb_vars, ind_vars, num_vars = [], [], []\n",
    "for var in X.columns:\n",
    "    if X[var].dtypes == 'O':\n",
    "        if len(X[var].unique()) > 5:\n",
    "            emb_vars.append(var)\n",
    "        else:\n",
    "            ind_vars.append(var)\n",
    "    else:\n",
    "        num_vars.append(var)\n",
    "print('Numerical variables are ', num_vars)\n",
    "print('Categorical variables that have at most 5 categories are ', ind_vars)\n",
    "print('Categorical variables that have more than 5 categories are ', emb_vars)\n",
    "\n",
    "# Create feature columns\n",
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in num_vars:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "# bucketized cols\n",
    "# age = feature_column.numeric_column('Prsn_Age')\n",
    "# age_buckets = feature_column.bucketized_column(age, boundaries=[16, 22, 35, 55, 65])\n",
    "# feature_columns.append(age_buckets)\n",
    "# indicator_columns\n",
    "for col_name in ind_vars:\n",
    "    categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, X[col_name].unique())\n",
    "    indicator_column = feature_column.indicator_column(categorical_column)\n",
    "    feature_columns.append(indicator_column)\n",
    "# embedding columns\n",
    "for col_name in emb_vars:\n",
    "    emb_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, X[col_name].unique())\n",
    "    col_embedding = feature_column.embedding_column(emb_column, dimension=5)\n",
    "    feature_columns.append(col_embedding)\n",
    "\n",
    "# Convert all setup into new dataset\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "X = feature_layer(dict(X)).numpy()\n",
    "print('New shape of the input data set:',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EiMyeEfZvoJ",
    "outputId": "a73f13c7-932e-49e5-bb80-6c9d506ad140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (30394, 59)\n",
      "Validation features shape: (7599, 59)\n",
      "Test features shape: (9499, 59)\n"
     ]
    }
   ],
   "source": [
    "# %% Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=48)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=48)\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation features shape:', X_val.shape)\n",
    "print('Test features shape:', X_test.shape)\n",
    "\n",
    "# %% standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ds5G6Pjhes9"
   },
   "source": [
    "# ALL mini functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Metrics\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,accuracy_score\n",
    "\n",
    "# %% Function to compare the prediction and true labels\n",
    "def get_accs2(label, pred_proba, tr_time=0,index=None):\n",
    "    prediction = pred_proba.argmax(axis=1)\n",
    "    cm = confusion_matrix(label, prediction)\n",
    "    length = cm.shape[0]\n",
    "    num_cases = len(label)\n",
    "    # global accuracy\n",
    "    glb_acc = np.trace(cm) / len(label)\n",
    "    ind_accs = cm / np.sum(cm, axis=1)[:, np.newaxis]\n",
    "    accs = [ind_accs[i, i] for i in range(length)]\n",
    "    cols = ['Class {}'.format(i) for i in range(length)]\n",
    "    # Global accuracy\n",
    "    accs.append(glb_acc)\n",
    "    # AUC\n",
    "    accs.append(roc_auc_score(label, pred_proba,multi_class='ovr'))\n",
    "    # G-mean\n",
    "    accs.append(geometric_mean_score(label, prediction, correction=0.001))\n",
    "    # Average perf\n",
    "    accs.append(np.mean(accs[-3:]))\n",
    "    # Training time\n",
    "    accs.append(np.round(tr_time,3))\n",
    "    cols = cols + ['Accuracy','AUC','G-mean','Avg_Pfm','Training Time']\n",
    "\n",
    "    out = np.array(accs).reshape(1, len(accs))\n",
    "    return pd.DataFrame(out, columns=cols,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GtuGulyVZvoL"
   },
   "outputs": [],
   "source": [
    "# %% Function to compare the prediction and true labels\n",
    "def get_accs(label, prediction, show=False):\n",
    "    cm = confusion_matrix(label, prediction)\n",
    "    length = cm.shape[0]\n",
    "    num_cases = len(label)\n",
    "    # global accuracy\n",
    "    glb_acc = np.trace(cm) / len(label)\n",
    "    ind_accs = cm / np.sum(cm, axis=1)[:, np.newaxis]\n",
    "    accs = [ind_accs[i, i] for i in range(length)]\n",
    "    index = ['Class {}'.format(i) for i in range(length)]\n",
    "    # Global accuracy\n",
    "    accs.append(glb_acc)\n",
    "    index.append('Overall Accuracy')\n",
    "    # G-mean\n",
    "    accs.append(geometric_mean_score(label, prediction, correction=0.001))\n",
    "    index.append('G-mean')\n",
    "    # Average perf\n",
    "    accs.append((glb_acc + accs[-1]) / 2)\n",
    "    index.append('Avg_Pfm')\n",
    "    if show:\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.heatmap(cm, xticklabels=np.arange(length), yticklabels=np.arange(length),\n",
    "                    annot=True, fmt='g', cmap=\"YlGnBu\")\n",
    "        plt.xlabel('Prediction')\n",
    "        plt.ylabel('Label')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(ind_accs * 100, xticklabels=np.arange(length), yticklabels=np.arange(length),\n",
    "                    annot=True, fmt='.2f', cmap=\"YlGnBu\")\n",
    "        plt.xlabel('Prediction')\n",
    "        plt.ylabel('Label')\n",
    "        plt.title('Normalized confusion matrix (%)')\n",
    "        plt.show()\n",
    "    out = np.array(accs).reshape(1, len(accs))\n",
    "    return pd.DataFrame(out, columns=index)\n",
    "\n",
    "def show_evolution(moni):\n",
    "    hist = pd.DataFrame(monitor.history)\n",
    "    no_metrics = np.int(hist.shape[1]/2)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6, 2), dpi=150)\n",
    "    for i in range(2):\n",
    "      hist.iloc[:,[i,no_metrics+i]].plot(ax=axes[i])\n",
    "    plt.show()\n",
    "# %% Produce an evaluation on the MLP model\n",
    "def evaluation(model, monitor, time, name):\n",
    "    # use the model to make predictions with the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    # Show evolution of the training process\n",
    "    # show_evolution(monitor)\n",
    "    # get the evaluation metrics\n",
    "    result = get_accs(y_test.values, y_pred)\n",
    "    result['Training Time'] = np.round(time, 3)\n",
    "    result.index = [name]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UDv2Pn6sZvoL",
    "outputId": "8a924722-bc7f-48c6-f927-72f63c69c69f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "DT\n",
      "RF\n",
      "     Class 0   Class 1   Class 2  Class 3   Class 4  Overall Accuracy  \\\n",
      "LR  0.525486  0.408203  0.165929   0.3875  0.647059          0.494789   \n",
      "DT  0.823114  0.169922  0.075221   0.0750  0.000000          0.709338   \n",
      "RF  0.635251  0.377930  0.006637   0.3625  0.647059          0.575324   \n",
      "\n",
      "      G-mean   Avg_Pfm  Training Time  \n",
      "LR  0.389148  0.441969          1.617  \n",
      "DT  0.060176  0.384757          0.415  \n",
      "RF  0.206309  0.390816          1.475  \n"
     ]
    }
   ],
   "source": [
    "wgt='balanced'\n",
    "clfs = [LogisticRegression(solver = 'lbfgs',class_weight=wgt),\n",
    "        DecisionTreeClassifier(class_weight=wgt),\n",
    "        RandomForestClassifier(max_depth=4,class_weight=wgt)]\n",
    "clf_names = ['LR','DT','RF']\n",
    "rsts = pd.DataFrame()\n",
    "for model, name in zip(clfs,clf_names):\n",
    "    start = time.time()\n",
    "    print(name)\n",
    "    model.fit(X_train, y_train.values)\n",
    "    # use the model to make predictions with the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    end= time.time()\n",
    "    # get the evaluation metrics\n",
    "    result = get_accs(y_test.values,y_pred)\n",
    "    result['Training Time'] = np.round(end-start,3)\n",
    "    result.index = [name]\n",
    "    rsts = rsts.append(result)\n",
    "print(rsts.iloc[:,-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff6Y5pBDhsXm"
   },
   "source": [
    "# MLP functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "npiMGh2TZvoK"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow_addons.metrics import CohenKappa,F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmzSlMdDZvoK",
    "outputId": "3e186bc5-a34c-42fc-90a7-98f73ea8d376"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.23969515734221616,\n",
       " 1: 1.85515625,\n",
       " 2: 4.199115826702034,\n",
       " 3: 23.86532663316583,\n",
       " 4: 111.74588235294118}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add weights\n",
    "weights = len(y) / (5 * np.bincount(y))\n",
    "cls_wgt = dict(zip(np.arange(5), weights))\n",
    "cls_wgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "w5IRiyFuZvoK"
   },
   "outputs": [],
   "source": [
    "def early_stops(metric_name):\n",
    "    es = EarlyStopping(monitor='val_'+ metric_name,\n",
    "                   verbose=1,\n",
    "                   patience=10,\n",
    "                   mode='max',\n",
    "                   restore_best_weights=True)\n",
    "    return es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nl6gMafpLK2P"
   },
   "source": [
    "# Ordinal multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "okwfjovXZvoK"
   },
   "outputs": [],
   "source": [
    "early_stop = {'accuracy':  tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
    "              'cohen_kappa': CohenKappa(num_classes=5,sparse_labels=True),\n",
    "              'f1_score': F1Score(num_classes=5,average=\"micro\",threshold=0.5),\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "SE-hMuQELoqr"
   },
   "outputs": [],
   "source": [
    "def create_mlp(metric):\n",
    "    MLP = Sequential([Dense(10,\n",
    "                           activation='relu',\n",
    "                           input_dim=X_train.shape[1]\n",
    "                           ),\n",
    "                      Dropout(0.5),\n",
    "                      Dense(5, activation='softmax')])\n",
    "    MLP.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                #loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[metric]\n",
    "               )\n",
    "    return MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hKQLxFOhLe41",
    "outputId": "c3cbb798-7d42-4aa7-d563-79a62558a4da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 30394 samples, validate on 7599 samples\n",
      "Epoch 1/50\n",
      "30394/30394 [==============================] - 2s 64us/sample - loss: 1.6252 - accuracy: 0.1536 - val_loss: 1.5830 - val_accuracy: 0.1171\n",
      "Epoch 2/50\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.5716 - accuracy: 0.2857 - val_loss: 1.4855 - val_accuracy: 0.4047\n",
      "Epoch 3/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.5426 - accuracy: 0.3874 - val_loss: 1.4720 - val_accuracy: 0.4749\n",
      "Epoch 4/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.5322 - accuracy: 0.4175 - val_loss: 1.4663 - val_accuracy: 0.4993\n",
      "Epoch 5/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.5073 - accuracy: 0.4100 - val_loss: 1.4649 - val_accuracy: 0.4945\n",
      "Epoch 6/50\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.5292 - accuracy: 0.4255 - val_loss: 1.4666 - val_accuracy: 0.4937\n",
      "Epoch 7/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4970 - accuracy: 0.4080 - val_loss: 1.4644 - val_accuracy: 0.5030\n",
      "Epoch 8/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.5135 - accuracy: 0.4205 - val_loss: 1.4650 - val_accuracy: 0.4755\n",
      "Epoch 9/50\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.4904 - accuracy: 0.4178 - val_loss: 1.4636 - val_accuracy: 0.4827\n",
      "Epoch 10/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.5029 - accuracy: 0.4219 - val_loss: 1.4623 - val_accuracy: 0.4841\n",
      "Epoch 11/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.4938 - accuracy: 0.4004 - val_loss: 1.4635 - val_accuracy: 0.4751\n",
      "Epoch 12/50\n",
      "30394/30394 [==============================] - 1s 42us/sample - loss: 1.4880 - accuracy: 0.3978 - val_loss: 1.4657 - val_accuracy: 0.4714\n",
      "Epoch 13/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4842 - accuracy: 0.3710 - val_loss: 1.4618 - val_accuracy: 0.4489\n",
      "Epoch 14/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4791 - accuracy: 0.3656 - val_loss: 1.4621 - val_accuracy: 0.4653\n",
      "Epoch 15/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4849 - accuracy: 0.3712 - val_loss: 1.4620 - val_accuracy: 0.4590\n",
      "Epoch 16/50\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.4681 - accuracy: 0.3649 - val_loss: 1.4620 - val_accuracy: 0.4398\n",
      "Epoch 17/50\n",
      "29888/30394 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.3711Restoring model weights from the end of the best epoch.\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4704 - accuracy: 0.3716 - val_loss: 1.4602 - val_accuracy: 0.4774\n",
      "Epoch 00017: early stopping\n",
      "cohen_kappa\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 30394 samples, validate on 7599 samples\n",
      "Epoch 1/50\n",
      "30394/30394 [==============================] - 3s 85us/sample - loss: 1.5836 - cohen_kappa: 0.0098 - val_loss: 1.5248 - val_cohen_kappa: 0.0348\n",
      "Epoch 2/50\n",
      "30394/30394 [==============================] - 2s 52us/sample - loss: 1.5374 - cohen_kappa: 0.0238 - val_loss: 1.5041 - val_cohen_kappa: 0.0561\n",
      "Epoch 3/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.5390 - cohen_kappa: 0.0332 - val_loss: 1.4875 - val_cohen_kappa: 0.0750\n",
      "Epoch 4/50\n",
      "30394/30394 [==============================] - 2s 53us/sample - loss: 1.5291 - cohen_kappa: 0.0412 - val_loss: 1.4730 - val_cohen_kappa: 0.0896\n",
      "Epoch 5/50\n",
      "30394/30394 [==============================] - 2s 56us/sample - loss: 1.5138 - cohen_kappa: 0.0465 - val_loss: 1.4665 - val_cohen_kappa: 0.0862\n",
      "Epoch 6/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4969 - cohen_kappa: 0.0440 - val_loss: 1.4619 - val_cohen_kappa: 0.0860\n",
      "Epoch 7/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.5022 - cohen_kappa: 0.0526 - val_loss: 1.4633 - val_cohen_kappa: 0.0879\n",
      "Epoch 8/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4872 - cohen_kappa: 0.0541 - val_loss: 1.4688 - val_cohen_kappa: 0.0915\n",
      "Epoch 9/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4917 - cohen_kappa: 0.0529 - val_loss: 1.4714 - val_cohen_kappa: 0.0905\n",
      "Epoch 10/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.4874 - cohen_kappa: 0.0502 - val_loss: 1.4684 - val_cohen_kappa: 0.0892\n",
      "Epoch 11/50\n",
      "30394/30394 [==============================] - 2s 56us/sample - loss: 1.4914 - cohen_kappa: 0.0492 - val_loss: 1.4644 - val_cohen_kappa: 0.0866\n",
      "Epoch 12/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.4802 - cohen_kappa: 0.0522 - val_loss: 1.4698 - val_cohen_kappa: 0.0840\n",
      "Epoch 13/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.4667 - cohen_kappa: 0.0491 - val_loss: 1.4657 - val_cohen_kappa: 0.0830\n",
      "Epoch 14/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4758 - cohen_kappa: 0.0443 - val_loss: 1.4721 - val_cohen_kappa: 0.0821\n",
      "Epoch 15/50\n",
      "30394/30394 [==============================] - 2s 51us/sample - loss: 1.4773 - cohen_kappa: 0.0476 - val_loss: 1.4741 - val_cohen_kappa: 0.0836\n",
      "Epoch 16/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.4743 - cohen_kappa: 0.0514 - val_loss: 1.4703 - val_cohen_kappa: 0.0810\n",
      "Epoch 17/50\n",
      "30394/30394 [==============================] - 2s 53us/sample - loss: 1.4768 - cohen_kappa: 0.0515 - val_loss: 1.4715 - val_cohen_kappa: 0.0859\n",
      "Epoch 18/50\n",
      "30016/30394 [============================>.] - ETA: 0s - loss: 1.4635 - cohen_kappa: 0.0492Restoring model weights from the end of the best epoch.\n",
      "30394/30394 [==============================] - 2s 52us/sample - loss: 1.4624 - cohen_kappa: 0.0493 - val_loss: 1.4741 - val_cohen_kappa: 0.0876\n",
      "Epoch 00018: early stopping\n",
      "f1_score\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 30394 samples, validate on 7599 samples\n",
      "Epoch 1/50\n",
      "30394/30394 [==============================] - 2s 67us/sample - loss: 1.6273 - f1_score: 0.1076 - val_loss: 1.6123 - val_f1_score: 0.0795\n",
      "Epoch 2/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.5878 - f1_score: 0.1150 - val_loss: 1.5903 - val_f1_score: 0.1007\n",
      "Epoch 3/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.5824 - f1_score: 0.1170 - val_loss: 1.5848 - val_f1_score: 0.1121\n",
      "Epoch 4/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.5711 - f1_score: 0.1216 - val_loss: 1.5797 - val_f1_score: 0.1208\n",
      "Epoch 5/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.5641 - f1_score: 0.1254 - val_loss: 1.5737 - val_f1_score: 0.1302\n",
      "Epoch 6/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.5522 - f1_score: 0.1274 - val_loss: 1.5703 - val_f1_score: 0.1305\n",
      "Epoch 7/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.5465 - f1_score: 0.1278 - val_loss: 1.5608 - val_f1_score: 0.1289\n",
      "Epoch 8/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.5413 - f1_score: 0.1259 - val_loss: 1.5342 - val_f1_score: 0.1244\n",
      "Epoch 9/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.5232 - f1_score: 0.1290 - val_loss: 1.5123 - val_f1_score: 0.1271\n",
      "Epoch 10/50\n",
      "30394/30394 [==============================] - 2s 51us/sample - loss: 1.5135 - f1_score: 0.1297 - val_loss: 1.4891 - val_f1_score: 0.1251\n",
      "Epoch 11/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.5005 - f1_score: 0.1313 - val_loss: 1.4795 - val_f1_score: 0.1344\n",
      "Epoch 12/50\n",
      "30394/30394 [==============================] - 1s 44us/sample - loss: 1.4963 - f1_score: 0.1344 - val_loss: 1.4697 - val_f1_score: 0.1382\n",
      "Epoch 13/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4993 - f1_score: 0.1333 - val_loss: 1.4687 - val_f1_score: 0.1377\n",
      "Epoch 14/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.4874 - f1_score: 0.1383 - val_loss: 1.4736 - val_f1_score: 0.1331\n",
      "Epoch 15/50\n",
      "30394/30394 [==============================] - 2s 49us/sample - loss: 1.4913 - f1_score: 0.1369 - val_loss: 1.4710 - val_f1_score: 0.1375\n",
      "Epoch 16/50\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.4762 - f1_score: 0.1393 - val_loss: 1.4701 - val_f1_score: 0.1429\n",
      "Epoch 17/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.4711 - f1_score: 0.1460 - val_loss: 1.4632 - val_f1_score: 0.1422\n",
      "Epoch 18/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.4808 - f1_score: 0.1475 - val_loss: 1.4752 - val_f1_score: 0.1401\n",
      "Epoch 19/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.4730 - f1_score: 0.1464 - val_loss: 1.4688 - val_f1_score: 0.1390\n",
      "Epoch 20/50\n",
      "30394/30394 [==============================] - 2s 49us/sample - loss: 1.4633 - f1_score: 0.1504 - val_loss: 1.4651 - val_f1_score: 0.1348\n",
      "Epoch 21/50\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.4671 - f1_score: 0.1468 - val_loss: 1.4585 - val_f1_score: 0.1289\n",
      "Epoch 22/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.4690 - f1_score: 0.1481 - val_loss: 1.4655 - val_f1_score: 0.1354\n",
      "Epoch 23/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4606 - f1_score: 0.1460 - val_loss: 1.4623 - val_f1_score: 0.1310\n",
      "Epoch 24/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.4693 - f1_score: 0.1485 - val_loss: 1.4608 - val_f1_score: 0.1287\n",
      "Epoch 25/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.4560 - f1_score: 0.1480 - val_loss: 1.4634 - val_f1_score: 0.1359\n",
      "Epoch 26/50\n",
      "29632/30394 [============================>.] - ETA: 0s - loss: 1.4623 - f1_score: 0.1529Restoring model weights from the end of the best epoch.\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4584 - f1_score: 0.1528 - val_loss: 1.4671 - val_f1_score: 0.1280\n",
      "Epoch 00026: early stopping\n",
      "                  Class 0   Class 1   Class 2  Class 3   Class 4  \\\n",
      "LR               0.525486  0.408203  0.165929   0.3875  0.647059   \n",
      "DT               0.823114  0.169922  0.075221   0.0750  0.000000   \n",
      "RF               0.635251  0.377930  0.006637   0.3625  0.647059   \n",
      "MLP accuracy     0.550214  0.298828  0.119469   0.3625  0.823529   \n",
      "MLP cohen_kappa  0.533813  0.480469  0.070796   0.2625  0.705882   \n",
      "MLP f1_score     0.499874  0.421875  0.134956   0.4125  0.470588   \n",
      "\n",
      "                 Overall Accuracy    G-mean   Avg_Pfm  Training Time  \n",
      "LR                       0.494789  0.389148  0.441969          1.617  \n",
      "DT                       0.709338  0.060176  0.384757          0.415  \n",
      "RF                       0.575324  0.206309  0.390816          1.475  \n",
      "MLP accuracy             0.501526  0.357799  0.429663         24.791  \n",
      "MLP cohen_kappa          0.504053  0.320174  0.412113         30.564  \n",
      "MLP f1_score             0.473313  0.353558  0.413435         39.220  \n"
     ]
    }
   ],
   "source": [
    "for name, metric in early_stop.items():\n",
    "    print(name)\n",
    "    model = create_mlp(metric)\n",
    "    start = time.time()\n",
    "    monitor = model.fit(X_train, y_train.values,\n",
    "                    callbacks=[early_stops(name)],\n",
    "                    class_weight = cls_wgt,\n",
    "                    validation_data=(X_val, y_val.values),\n",
    "                    verbose=0, epochs=50)\n",
    "    end = time.time()\n",
    "    rsts = rsts.append(evaluation(model, monitor, end - start,  'MLP '+ name))\n",
    "print(rsts.iloc[:,-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YC-R3A56Lxn7"
   },
   "source": [
    "# One-hot encoded multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BICiC9fdwOSw"
   },
   "outputs": [],
   "source": [
    " early_stop = {'auc':       tf.keras.metrics.AUC(name='auc'),\n",
    "     'accuracy':  tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "               'precision': tf.keras.metrics.Precision(name='precision'),\n",
    "               'recall':    tf.keras.metrics.Recall(name='recall'),\n",
    "               \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "0TY-s6q5ZvoK"
   },
   "outputs": [],
   "source": [
    "def create_mlp(metric):\n",
    "    MLP = Sequential([Dense(10,\n",
    "                           activation='relu',\n",
    "                           input_dim=X_train.shape[1]\n",
    "                           ),\n",
    "                      Dropout(0.5),\n",
    "                      Dense(5, activation='softmax')])\n",
    "    MLP.compile(optimizer='adam',\n",
    "                #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[metric]\n",
    "               )\n",
    "    return MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "UbG3CxlaUxKp"
   },
   "outputs": [],
   "source": [
    "#rsts = rsts.iloc[:6,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "78EjwO6URzui",
    "outputId": "4829623c-88b1-489f-f63e-e06883fb5780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 30394 samples, validate on 7599 samples\n",
      "Epoch 1/50\n",
      "30394/30394 [==============================] - 2s 77us/sample - loss: 1.5872 - auc: 0.4774 - val_loss: 1.5191 - val_auc: 0.5279\n",
      "Epoch 2/50\n",
      "30394/30394 [==============================] - 2s 52us/sample - loss: 1.5582 - auc: 0.5550 - val_loss: 1.5326 - val_auc: 0.6132\n",
      "Epoch 3/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.5436 - auc: 0.6273 - val_loss: 1.4896 - val_auc: 0.6959\n",
      "Epoch 4/50\n",
      "30394/30394 [==============================] - 2s 53us/sample - loss: 1.5239 - auc: 0.6932 - val_loss: 1.4704 - val_auc: 0.7602\n",
      "Epoch 5/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.5126 - auc: 0.7109 - val_loss: 1.4872 - val_auc: 0.7740\n",
      "Epoch 6/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.5198 - auc: 0.7359 - val_loss: 1.4639 - val_auc: 0.7890\n",
      "Epoch 7/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.5014 - auc: 0.7418 - val_loss: 1.4715 - val_auc: 0.7916\n",
      "Epoch 8/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.5163 - auc: 0.7485 - val_loss: 1.4745 - val_auc: 0.7998\n",
      "Epoch 9/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4982 - auc: 0.7472 - val_loss: 1.4694 - val_auc: 0.7851\n",
      "Epoch 10/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4939 - auc: 0.7362 - val_loss: 1.4660 - val_auc: 0.7904\n",
      "Epoch 11/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.4913 - auc: 0.7384 - val_loss: 1.4690 - val_auc: 0.7974\n",
      "Epoch 12/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4706 - auc: 0.7420 - val_loss: 1.4823 - val_auc: 0.7931\n",
      "Epoch 13/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4842 - auc: 0.7321 - val_loss: 1.4806 - val_auc: 0.7845\n",
      "Epoch 14/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.4893 - auc: 0.7204 - val_loss: 1.4835 - val_auc: 0.7730\n",
      "Epoch 15/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4801 - auc: 0.7284 - val_loss: 1.4888 - val_auc: 0.8049\n",
      "Epoch 16/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4631 - auc: 0.7398 - val_loss: 1.4896 - val_auc: 0.8009\n",
      "Epoch 17/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4740 - auc: 0.7485 - val_loss: 1.4879 - val_auc: 0.8169\n",
      "Epoch 18/50\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4808 - auc: 0.7480 - val_loss: 1.4557 - val_auc: 0.7930\n",
      "Epoch 19/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.4742 - auc: 0.7280 - val_loss: 1.4618 - val_auc: 0.7951\n",
      "Epoch 20/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.4702 - auc: 0.7293 - val_loss: 1.4630 - val_auc: 0.7976\n",
      "Epoch 21/50\n",
      "30394/30394 [==============================] - 2s 52us/sample - loss: 1.4698 - auc: 0.7250 - val_loss: 1.4678 - val_auc: 0.7926\n",
      "Epoch 22/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.4762 - auc: 0.7282 - val_loss: 1.4712 - val_auc: 0.7853\n",
      "Epoch 23/50\n",
      "30394/30394 [==============================] - 2s 53us/sample - loss: 1.4789 - auc: 0.7239 - val_loss: 1.4885 - val_auc: 0.7901\n",
      "Epoch 24/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.4632 - auc: 0.7239 - val_loss: 1.4780 - val_auc: 0.7837\n",
      "Epoch 25/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.4620 - auc: 0.7327 - val_loss: 1.4834 - val_auc: 0.7770\n",
      "Epoch 26/50\n",
      "30394/30394 [==============================] - 2s 55us/sample - loss: 1.4616 - auc: 0.7218 - val_loss: 1.4912 - val_auc: 0.7811\n",
      "Epoch 27/50\n",
      "29920/30394 [============================>.] - ETA: 0s - loss: 1.4667 - auc: 0.7260Restoring model weights from the end of the best epoch.\n",
      "30394/30394 [==============================] - 2s 54us/sample - loss: 1.4628 - auc: 0.7259 - val_loss: 1.4869 - val_auc: 0.7829\n",
      "Epoch 00027: early stopping\n",
      "accuracy\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 30394 samples, validate on 7599 samples\n",
      "Epoch 1/50\n",
      "30394/30394 [==============================] - 2s 63us/sample - loss: 1.6177 - accuracy: 0.2506 - val_loss: 1.6185 - val_accuracy: 0.3428\n",
      "Epoch 2/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.5887 - accuracy: 0.3198 - val_loss: 1.5774 - val_accuracy: 0.4110\n",
      "Epoch 3/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.5581 - accuracy: 0.3661 - val_loss: 1.5224 - val_accuracy: 0.4526\n",
      "Epoch 4/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.5387 - accuracy: 0.3646 - val_loss: 1.4991 - val_accuracy: 0.4270\n",
      "Epoch 5/50\n",
      "30394/30394 [==============================] - 1s 45us/sample - loss: 1.5331 - accuracy: 0.3505 - val_loss: 1.5040 - val_accuracy: 0.4405\n",
      "Epoch 6/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.5267 - accuracy: 0.3769 - val_loss: 1.5018 - val_accuracy: 0.4397\n",
      "Epoch 7/50\n",
      "30394/30394 [==============================] - 1s 45us/sample - loss: 1.5138 - accuracy: 0.3649 - val_loss: 1.4989 - val_accuracy: 0.4431\n",
      "Epoch 8/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.5045 - accuracy: 0.3739 - val_loss: 1.4930 - val_accuracy: 0.4518\n",
      "Epoch 9/50\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.5011 - accuracy: 0.3690 - val_loss: 1.4818 - val_accuracy: 0.4657\n",
      "Epoch 10/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.4893 - accuracy: 0.3668 - val_loss: 1.4884 - val_accuracy: 0.4373\n",
      "Epoch 11/50\n",
      "30394/30394 [==============================] - 1s 45us/sample - loss: 1.5033 - accuracy: 0.3673 - val_loss: 1.4885 - val_accuracy: 0.4436\n",
      "Epoch 12/50\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.4982 - accuracy: 0.3764 - val_loss: 1.4897 - val_accuracy: 0.4360\n",
      "Epoch 13/50\n",
      "30394/30394 [==============================] - 1s 45us/sample - loss: 1.4947 - accuracy: 0.3679 - val_loss: 1.4963 - val_accuracy: 0.4222\n",
      "Epoch 14/50\n",
      "30394/30394 [==============================] - 1s 45us/sample - loss: 1.4823 - accuracy: 0.3685 - val_loss: 1.4833 - val_accuracy: 0.4585\n",
      "Epoch 15/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4850 - accuracy: 0.3706 - val_loss: 1.4816 - val_accuracy: 0.4387\n",
      "Epoch 16/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.5115 - accuracy: 0.3769 - val_loss: 1.4749 - val_accuracy: 0.4505\n",
      "Epoch 17/50\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.4731 - accuracy: 0.3851 - val_loss: 1.4884 - val_accuracy: 0.4469\n",
      "Epoch 18/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.4777 - accuracy: 0.3811 - val_loss: 1.4683 - val_accuracy: 0.4664\n",
      "Epoch 19/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.4769 - accuracy: 0.3753 - val_loss: 1.4617 - val_accuracy: 0.4628\n",
      "Epoch 20/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.4642 - accuracy: 0.3754 - val_loss: 1.4852 - val_accuracy: 0.4527\n",
      "Epoch 21/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.4751 - accuracy: 0.3784 - val_loss: 1.4994 - val_accuracy: 0.4727\n",
      "Epoch 22/50\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.4670 - accuracy: 0.3935 - val_loss: 1.4972 - val_accuracy: 0.5056\n",
      "Epoch 23/50\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.4662 - accuracy: 0.3982 - val_loss: 1.5069 - val_accuracy: 0.4520\n",
      "Epoch 24/50\n",
      "30394/30394 [==============================] - 1s 45us/sample - loss: 1.4732 - accuracy: 0.3705 - val_loss: 1.5021 - val_accuracy: 0.4924\n",
      "Epoch 25/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.4857 - accuracy: 0.3940 - val_loss: 1.5022 - val_accuracy: 0.4722\n",
      "Epoch 26/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.4550 - accuracy: 0.3796 - val_loss: 1.5010 - val_accuracy: 0.4622\n",
      "Epoch 27/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.4529 - accuracy: 0.3939 - val_loss: 1.4999 - val_accuracy: 0.4834\n",
      "Epoch 28/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.4657 - accuracy: 0.3904 - val_loss: 1.5014 - val_accuracy: 0.4884\n",
      "Epoch 29/50\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.4687 - accuracy: 0.3908 - val_loss: 1.4977 - val_accuracy: 0.4626\n",
      "Epoch 30/50\n",
      "30394/30394 [==============================] - 1s 45us/sample - loss: 1.4747 - accuracy: 0.3836 - val_loss: 1.4987 - val_accuracy: 0.4849\n",
      "Epoch 31/50\n",
      "30394/30394 [==============================] - 1s 46us/sample - loss: 1.4620 - accuracy: 0.3949 - val_loss: 1.4889 - val_accuracy: 0.4694\n",
      "Epoch 32/50\n",
      "30048/30394 [============================>.] - ETA: 0s - loss: 1.4712 - accuracy: 0.3783Restoring model weights from the end of the best epoch.\n",
      "30394/30394 [==============================] - 1s 47us/sample - loss: 1.4699 - accuracy: 0.3781 - val_loss: 1.5024 - val_accuracy: 0.4456\n",
      "Epoch 00032: early stopping\n",
      "precision\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 30394 samples, validate on 7599 samples\n",
      "Epoch 1/50\n",
      "30394/30394 [==============================] - 2s 73us/sample - loss: 1.6276 - precision: 0.4591 - val_loss: 1.6124 - val_precision: 0.5761\n",
      "Epoch 2/50\n",
      "30394/30394 [==============================] - 1s 44us/sample - loss: 1.5570 - precision: 0.6602 - val_loss: 1.4653 - val_precision: 0.7712\n",
      "Epoch 3/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.5265 - precision: 0.6768 - val_loss: 1.4602 - val_precision: 0.7834\n",
      "Epoch 4/50\n",
      "30394/30394 [==============================] - 2s 49us/sample - loss: 1.5264 - precision: 0.6696 - val_loss: 1.4625 - val_precision: 0.7613\n",
      "Epoch 5/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.5121 - precision: 0.6178 - val_loss: 1.4598 - val_precision: 0.6518\n",
      "Epoch 6/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.5062 - precision: 0.5784 - val_loss: 1.4569 - val_precision: 0.6703\n",
      "Epoch 7/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.5070 - precision: 0.5623 - val_loss: 1.4614 - val_precision: 0.6936\n",
      "Epoch 8/50\n",
      "30394/30394 [==============================] - 2s 49us/sample - loss: 1.4908 - precision: 0.5875 - val_loss: 1.4624 - val_precision: 0.6417\n",
      "Epoch 9/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4901 - precision: 0.5748 - val_loss: 1.4544 - val_precision: 0.6420\n",
      "Epoch 10/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.4795 - precision: 0.5493 - val_loss: 1.4561 - val_precision: 0.6015\n",
      "Epoch 11/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4807 - precision: 0.5345 - val_loss: 1.4548 - val_precision: 0.5868\n",
      "Epoch 12/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4843 - precision: 0.5505 - val_loss: 1.4964 - val_precision: 0.6275\n",
      "Epoch 13/50\n",
      "29920/30394 [============================>.] - ETA: 0s - loss: 1.4941 - precision: 0.5540Restoring model weights from the end of the best epoch.\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4922 - precision: 0.5549 - val_loss: 1.4946 - val_precision: 0.6650\n",
      "Epoch 00013: early stopping\n",
      "recall\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 30394 samples, validate on 7599 samples\n",
      "Epoch 1/50\n",
      "30394/30394 [==============================] - 3s 85us/sample - loss: 1.6377 - recall: 0.0356 - val_loss: 1.6254 - val_recall: 0.0111\n",
      "Epoch 2/50\n",
      "30394/30394 [==============================] - 2s 51us/sample - loss: 1.6062 - recall: 0.0532 - val_loss: 1.6144 - val_recall: 0.0383\n",
      "Epoch 3/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.5868 - recall: 0.1218 - val_loss: 1.6026 - val_recall: 0.1055\n",
      "Epoch 4/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.5754 - recall: 0.1701 - val_loss: 1.5913 - val_recall: 0.2137\n",
      "Epoch 5/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.5343 - recall: 0.1992 - val_loss: 1.5177 - val_recall: 0.2456\n",
      "Epoch 6/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.5268 - recall: 0.2211 - val_loss: 1.4818 - val_recall: 0.2975\n",
      "Epoch 7/50\n",
      "30394/30394 [==============================] - 2s 50us/sample - loss: 1.5095 - recall: 0.2519 - val_loss: 1.4824 - val_recall: 0.2982\n",
      "Epoch 8/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.5050 - recall: 0.2586 - val_loss: 1.4894 - val_recall: 0.2915\n",
      "Epoch 9/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4953 - recall: 0.2614 - val_loss: 1.4814 - val_recall: 0.3271\n",
      "Epoch 10/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.4889 - recall: 0.2763 - val_loss: 1.4882 - val_recall: 0.3235\n",
      "Epoch 11/50\n",
      "30394/30394 [==============================] - 2s 49us/sample - loss: 1.4909 - recall: 0.2791 - val_loss: 1.4895 - val_recall: 0.3483\n",
      "Epoch 12/50\n",
      "30394/30394 [==============================] - 2s 52us/sample - loss: 1.4746 - recall: 0.2967 - val_loss: 1.4852 - val_recall: 0.3824\n",
      "Epoch 13/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.4793 - recall: 0.3065 - val_loss: 1.4854 - val_recall: 0.3123\n",
      "Epoch 14/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4731 - recall: 0.2820 - val_loss: 1.4959 - val_recall: 0.3085\n",
      "Epoch 15/50\n",
      "30394/30394 [==============================] - 2s 49us/sample - loss: 1.4817 - recall: 0.2842 - val_loss: 1.4905 - val_recall: 0.3575\n",
      "Epoch 16/50\n",
      "30394/30394 [==============================] - 1s 48us/sample - loss: 1.4801 - recall: 0.2907 - val_loss: 1.4878 - val_recall: 0.3612\n",
      "Epoch 17/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.4711 - recall: 0.3033 - val_loss: 1.4851 - val_recall: 0.3573\n",
      "Epoch 18/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.4788 - recall: 0.3092 - val_loss: 1.4995 - val_recall: 0.3360\n",
      "Epoch 19/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.4650 - recall: 0.3121 - val_loss: 1.4943 - val_recall: 0.3462\n",
      "Epoch 20/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.4769 - recall: 0.3082 - val_loss: 1.4790 - val_recall: 0.3461\n",
      "Epoch 21/50\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.4771 - recall: 0.3168 - val_loss: 1.4823 - val_recall: 0.3808\n",
      "Epoch 22/50\n",
      "30144/30394 [============================>.] - ETA: 0s - loss: 1.4602 - recall: 0.3162Restoring model weights from the end of the best epoch.\n",
      "30394/30394 [==============================] - 1s 49us/sample - loss: 1.4603 - recall: 0.3164 - val_loss: 1.4849 - val_recall: 0.3698\n",
      "Epoch 00022: early stopping\n",
      "                   Class 0   Class 1   Class 2  Class 3   Class 4  \\\n",
      "LR                0.525486  0.408203  0.165929   0.3875  0.647059   \n",
      "DT                0.823114  0.169922  0.075221   0.0750  0.000000   \n",
      "RF                0.635251  0.377930  0.006637   0.3625  0.647059   \n",
      "MLP accuracy      0.550214  0.298828  0.119469   0.3625  0.823529   \n",
      "MLP cohen_kappa   0.533813  0.480469  0.070796   0.2625  0.705882   \n",
      "MLP f1_score      0.499874  0.421875  0.134956   0.4125  0.470588   \n",
      "MLP 1H auc        0.563210  0.412109  0.070796   0.3500  0.764706   \n",
      "MLP 1H accuracy   0.555009  0.414062  0.139381   0.2875  0.529412   \n",
      "MLP 1H precision  0.645471  0.212891  0.092920   0.1875  0.823529   \n",
      "MLP 1H recall     0.623013  0.280273  0.097345   0.4375  0.352941   \n",
      "\n",
      "                  Overall Accuracy    G-mean   Avg_Pfm  Training Time  \n",
      "LR                        0.494789  0.389148  0.441969          1.617  \n",
      "DT                        0.709338  0.060176  0.384757          0.415  \n",
      "RF                        0.575324  0.206309  0.390816          1.475  \n",
      "MLP accuracy              0.501526  0.357799  0.429663         24.791  \n",
      "MLP cohen_kappa           0.504053  0.320174  0.412113         30.564  \n",
      "MLP f1_score              0.473313  0.353558  0.413435         39.220  \n",
      "MLP 1H auc                0.522055  0.337794  0.429924         45.207  \n",
      "MLP 1H accuracy           0.517739  0.344826  0.431282         45.621  \n",
      "MLP 1H precision          0.569007  0.287717  0.428362         19.930  \n",
      "MLP 1H recall             0.559006  0.304659  0.431833         34.081  \n"
     ]
    }
   ],
   "source": [
    "for name, metric in early_stop.items():\n",
    "    print(name)\n",
    "    model = create_mlp(metric)\n",
    "    start = time.time()\n",
    "    monitor = model.fit(X_train, pd.get_dummies(y_train).values,\n",
    "                    callbacks=[early_stops(name)],\n",
    "                    class_weight = cls_wgt,\n",
    "                    validation_data=(X_val, pd.get_dummies(y_val).values),\n",
    "                    verbose=0, epochs=50)\n",
    "    end = time.time()\n",
    "    rsts = rsts.append(evaluation(model, monitor, end - start,  'MLP 1H '+ name))\n",
    "print(rsts.iloc[:,-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsts.to_csv('VCA_Early_stopping.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "VCA_2.1_MLP_earlystopping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
