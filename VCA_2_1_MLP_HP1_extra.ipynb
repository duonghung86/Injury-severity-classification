{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/duonghung86/Injury-severity-classification/blob/main/VCA_2_1_MLP_earlystopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bo-3JT-1cl14",
    "outputId": "c710009f-72c5-44ef-9e68-7b27f7c8d34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 270.0 gigabytes of available RAM\n",
      "\n",
      "Current system-wide CPU utilization %:  33.3\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory,cpu_percent\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "print('Current system-wide CPU utilization %: ',cpu_percent())\n",
    "#Remove all warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ond2r97pZvoF",
    "outputId": "090a81b4-6b1f-46d8-abb5-725257820a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "from collections import Counter\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler # Standardization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Machine learning algos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Imblearn\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler,BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,NearMiss,EditedNearestNeighbours\n",
    "\n",
    "# Grid search\n",
    "from kerastuner.tuners import RandomSearch,Hyperband,BayesianOptimization\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import feature_column  # for data wrangling\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy,CategoricalCrossentropy\n",
    "from tensorflow.keras.layers import Dense,Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy,CategoricalAccuracy\n",
    "from tensorflow_addons.metrics import CohenKappa,F1Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMFYXIMkFSak",
    "outputId": "d80430a7-b93b-421a-a2d9-3b1cbf3e5ba5"
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/duonghung86/Injury-severity-classification/blob/main/Prepared%20Texas%202019.zip?raw=true' \n",
    "data_path = tf.keras.utils.get_file(origin=url, fname=url.split('/')[-1].split('?')[0], extract=True)\n",
    "data_path = data_path.replace('%20',' ').replace('.zip','.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "UPLNCpWjZvoG",
    "outputId": "7d652183-53ce-4328-aada-ea393cc2efce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(949856, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prsn_Injry_Sev</th>\n",
       "      <th>Prsn_Age</th>\n",
       "      <th>Prsn_Gndr</th>\n",
       "      <th>Wthr_Cond</th>\n",
       "      <th>Light_Cond</th>\n",
       "      <th>Surf_Cond</th>\n",
       "      <th>Veh_Body_Styl</th>\n",
       "      <th>Prsn_Rest</th>\n",
       "      <th>Prsn_Drg_Rslt</th>\n",
       "      <th>Harm_Evnt</th>\n",
       "      <th>Rural</th>\n",
       "      <th>Crash_Speed_Limit</th>\n",
       "      <th>Road_Algn</th>\n",
       "      <th>Veh_Mod_Year</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Crash_season</th>\n",
       "      <th>Part_of_day</th>\n",
       "      <th>Collsn_type</th>\n",
       "      <th>Collsn_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>MALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PASSENGER CAR, 2-DOOR</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>STRAIGHT, LEVEL</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>ONE STRAIGHT-ONE LEFT TURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>MALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PASSENGER CAR, 2-DOOR</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>STRAIGHT, LEVEL</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>ONE STRAIGHT-ONE LEFT TURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PICKUP</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>CURVE, LEVEL</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>BOTH LEFT TURN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prsn_Injry_Sev  Prsn_Age Prsn_Gndr Wthr_Cond Light_Cond Surf_Cond  \\\n",
       "0               0        26      MALE     CLEAR   DAYLIGHT       DRY   \n",
       "1               0        52      MALE     CLEAR   DAYLIGHT       DRY   \n",
       "2               0        27    FEMALE     CLEAR   DAYLIGHT       DRY   \n",
       "\n",
       "           Veh_Body_Styl            Prsn_Rest   Prsn_Drg_Rslt  \\\n",
       "0  PASSENGER CAR, 2-DOOR  SHOULDER & LAP BELT  Not Applicable   \n",
       "1  PASSENGER CAR, 2-DOOR  SHOULDER & LAP BELT  Not Applicable   \n",
       "2                 PICKUP  SHOULDER & LAP BELT  Not Applicable   \n",
       "\n",
       "                    Harm_Evnt  Rural  Crash_Speed_Limit        Road_Algn  \\\n",
       "0  MOTOR VEHICLE IN TRANSPORT      0                 -1  STRAIGHT, LEVEL   \n",
       "1  MOTOR VEHICLE IN TRANSPORT      0                 -1  STRAIGHT, LEVEL   \n",
       "2  MOTOR VEHICLE IN TRANSPORT      1                 -1     CURVE, LEVEL   \n",
       "\n",
       "   Veh_Mod_Year  Weekend  Crash_season  Part_of_day     Collsn_type  \\\n",
       "0            33        1             3            3  SAME DIRECTION   \n",
       "1            19        1             3            3  SAME DIRECTION   \n",
       "2            16        1             3            4  SAME DIRECTION   \n",
       "\n",
       "                  Collsn_name  \n",
       "0  ONE STRAIGHT-ONE LEFT TURN  \n",
       "1  ONE STRAIGHT-ONE LEFT TURN  \n",
       "2              BOTH LEFT TURN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(data_path)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1CDPbDPYZvoH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949856, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's just use 80% of the total dataset\n",
    "#df, _ = train_test_split(df, test_size=0.9,stratify = df['Prsn_Injry_Sev'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEKbv3R9ZvoH",
    "outputId": "93f16610-1110-4ffe-9c66-f4dea88ae652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All target values:\n",
      "0    792558\n",
      "1    102409\n",
      "2     45242\n",
      "3      7951\n",
      "4      1696\n",
      "Name: Prsn_Injry_Sev, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df['Prsn_Injry_Sev']\n",
    "print('All target values:')\n",
    "print(y.value_counts())\n",
    "X = df.drop(columns=['Prsn_Injry_Sev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUDtEBDsZvoI",
    "outputId": "b311b931-acd8-453a-95f9-b54c0b572d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical variables are  ['Prsn_Age', 'Rural', 'Crash_Speed_Limit', 'Veh_Mod_Year', 'Weekend', 'Crash_season', 'Part_of_day']\n",
      "Categorical variables that have at most 5 categories are  ['Prsn_Gndr', 'Prsn_Drg_Rslt', 'Collsn_type']\n",
      "Categorical variables that have more than 5 categories are  ['Wthr_Cond', 'Light_Cond', 'Surf_Cond', 'Veh_Body_Styl', 'Prsn_Rest', 'Harm_Evnt', 'Road_Algn', 'Collsn_name']\n",
      "WARNING:tensorflow:From /project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "New shape of the input data set: (949856, 59)\n"
     ]
    }
   ],
   "source": [
    "# %% Data wrangling -------------\n",
    "# Classify variable type\n",
    "emb_vars, ind_vars, num_vars = [], [], []\n",
    "for var in X.columns:\n",
    "    if X[var].dtypes == 'O':\n",
    "        if len(X[var].unique()) > 5:\n",
    "            emb_vars.append(var)\n",
    "        else:\n",
    "            ind_vars.append(var)\n",
    "    else:\n",
    "        num_vars.append(var)\n",
    "print('Numerical variables are ', num_vars)\n",
    "print('Categorical variables that have at most 5 categories are ', ind_vars)\n",
    "print('Categorical variables that have more than 5 categories are ', emb_vars)\n",
    "\n",
    "# Create feature columns\n",
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in num_vars:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "# bucketized cols\n",
    "# age = feature_column.numeric_column('Prsn_Age')\n",
    "# age_buckets = feature_column.bucketized_column(age, boundaries=[16, 22, 35, 55, 65])\n",
    "# feature_columns.append(age_buckets)\n",
    "# indicator_columns\n",
    "for col_name in ind_vars:\n",
    "    categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, X[col_name].unique())\n",
    "    indicator_column = feature_column.indicator_column(categorical_column)\n",
    "    feature_columns.append(indicator_column)\n",
    "# embedding columns\n",
    "for col_name in emb_vars:\n",
    "    emb_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, X[col_name].unique())\n",
    "    col_embedding = feature_column.embedding_column(emb_column, dimension=5)\n",
    "    feature_columns.append(col_embedding)\n",
    "\n",
    "# Convert all setup into new dataset\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "X = feature_layer(dict(X)).numpy()\n",
    "print('New shape of the input data set:',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EiMyeEfZvoJ",
    "outputId": "a73f13c7-932e-49e5-bb80-6c9d506ad140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (607907, 59)\n",
      "Validation features shape: (151977, 59)\n",
      "Test features shape: (189972, 59)\n"
     ]
    }
   ],
   "source": [
    "# %% Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=48)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=48)\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation features shape:', X_val.shape)\n",
    "print('Test features shape:', X_test.shape)\n",
    "\n",
    "# %% standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ds5G6Pjhes9"
   },
   "source": [
    "# ALL mini functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Metrics\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,accuracy_score\n",
    "\n",
    "# %% Function to compare the prediction and true labels\n",
    "def get_accs(label, pred_proba, tr_time=0,index=None):\n",
    "    prediction = pred_proba.argmax(axis=1)\n",
    "    cm = confusion_matrix(label, prediction)\n",
    "    length = cm.shape[0]\n",
    "    num_cases = len(label)\n",
    "    # global accuracy\n",
    "    glb_acc = np.trace(cm) / len(label)\n",
    "    ind_accs = cm / np.sum(cm, axis=1)[:, np.newaxis]\n",
    "    accs = [ind_accs[i, i] for i in range(length)]\n",
    "    cols = ['Class {}'.format(i) for i in range(length)]\n",
    "    # Global accuracy\n",
    "    accs.append(glb_acc)\n",
    "    # AUC\n",
    "    accs.append(roc_auc_score(label, pred_proba,multi_class='ovr'))\n",
    "    # G-mean\n",
    "    accs.append(geometric_mean_score(label, prediction, correction=0.001))\n",
    "    # Average perf\n",
    "    accs.append(np.mean(accs[-3:]))\n",
    "    # Training time\n",
    "    accs.append(np.round(tr_time,3))\n",
    "    cols = cols + ['Accuracy','AUC','G-mean','Avg_Pfm','Training Time']\n",
    "\n",
    "    out = np.array(accs).reshape(1, len(accs))\n",
    "    return pd.DataFrame(out, columns=cols,index=[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with class weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff6Y5pBDhsXm"
   },
   "source": [
    "# MLP functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmzSlMdDZvoK",
    "outputId": "3e186bc5-a34c-42fc-90a7-98f73ea8d376"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.23969347661941065,\n",
       " 1: 1.8550434079431195,\n",
       " 2: 4.199122746425364,\n",
       " 3: 23.891019846728238,\n",
       " 4: 111.95340699815839}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add weights\n",
    "weights = len(y_train) / (5 * np.bincount(y_train))\n",
    "cls_wgt = dict(zip(np.arange(5), weights))\n",
    "cls_wgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "w5IRiyFuZvoK"
   },
   "outputs": [],
   "source": [
    "def early_stops(metric_name):\n",
    "    es = EarlyStopping(monitor='val_'+ metric_name,\n",
    "                   verbose=1, patience=10, mode='max',\n",
    "                   restore_best_weights=True)\n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 2048\n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [SparseCategoricalAccuracy(name='accuracy'),\n",
    "           CohenKappa(name='kappa',num_classes=5,sparse_labels=True),\n",
    "           F1Score(name='f1_micro', num_classes=5,average=\"micro\",threshold=0.5),\n",
    "          ]\n",
    "def create_mlp():\n",
    "    MLP = Sequential([Dense(10,\n",
    "                           activation='relu',\n",
    "                           input_dim=X_train.shape[1],\n",
    "                           ),\n",
    "                      Dropout(0.5),\n",
    "                      Dense(5, activation='softmax')])\n",
    "    MLP.compile(optimizer='adam',\n",
    "                loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=METRICS\n",
    "               )\n",
    "    return MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Resampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under sampling ...\n",
      "Counter({0: 65541, 1: 65541, 2: 28954, 3: 5089, 4: 1086})\n",
      "over sampling #2 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Counter({0: 65541, 1: 65541, 2: 65541, 3: 65541, 4: 65541}),\n",
       " 70.37647199630737)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dict = Counter(y_train)\n",
    "\n",
    "start = time.time()\n",
    "res = RandomUnderSampler(random_state = 54, sampling_strategy={0: y_dict[1]})\n",
    "print('under sampling ...')\n",
    "X_res, y_res = res.fit_resample(X_train, y_train)\n",
    "\n",
    "res = SMOTE(random_state = 34,sampling_strategy='not majority')\n",
    "print(Counter(y_res))\n",
    "print('over sampling #2 ...')\n",
    "X_res, y_res = res.fit_resample(X_res, y_res)\n",
    "end = time.time()\n",
    "res_time = end-start\n",
    "Counter(y_res),res_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with Hybrid Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "         Accuracy       AUC    G-mean   Avg_Pfm  Training Time\n",
      "MLP-W-1  0.545780  0.631388  0.244335  0.473834          6.282\n",
      "MLP-W-2  0.509422  0.702490  0.353039  0.521650         10.828\n",
      "MLP-W-3  0.549086  0.652409  0.193501  0.464998          6.165\n"
     ]
    }
   ],
   "source": [
    "rsts = pd.DataFrame()\n",
    "for i in range(3):\n",
    "    model = create_mlp()\n",
    "    start = time.time()\n",
    "    monitor = model.fit(X_res, y_res,\n",
    "                        callbacks=[early_stops('accuracy')],\n",
    "                        validation_data=(X_val,y_val),\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        verbose=VERBOSE, epochs=EPOCH\n",
    "                       )\n",
    "    end = time.time()\n",
    "    # use the model to make predictions with the test data\n",
    "    Y_pred = model.predict(X_test)\n",
    "    rsts = rsts.append(get_accs(y_test.values,Y_pred,end-start,'MLP-W-'+str(i+1)))\n",
    "print(rsts.iloc[:,5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up grid search\n",
    "\n",
    "We will investigates the following parameters:\n",
    "\n",
    "- Initial weights\n",
    "- Activation function\n",
    "- Number of nodes\n",
    "- Dropout rate\n",
    "- Early Stop\n",
    "- Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    hp_units = hp.Int('units', min_value=5, max_value=20, step=5)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "    hp_dos = hp.Float('dropouts',min_value=0.2, max_value=0.3, step=0.1)\n",
    "    hp_acts = hp.Choice('activation', values = ['relu','sigmoid','tanh','selu'])\n",
    "    keins = ['uniform', 'normal', 'zeros', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "    hp_keins = hp.Choice('kernel_ini', values = keins) \n",
    "    model = Sequential([Dense(hp_units,\n",
    "                           activation=hp_acts,\n",
    "                           input_dim=X_train.shape[1],\n",
    "                            kernel_initializer= hp_keins \n",
    "                           ),\n",
    "                      Dropout(hp_dos),\n",
    "                      Dense(5, activation='softmax')])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=METRICS\n",
    "               )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metr = ['loss','accuracy','kappa','f1_micro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 30\n",
    "FACTOR = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00029: early stopping\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Tuning time is 796.44\n",
      "{'units': 20, 'learning_rate': 0.01, 'dropouts': 0.2, 'activation': 'sigmoid', 'kernel_ini': 'glorot_uniform', 'tuner/epochs': 30, 'tuner/initial_epoch': 6, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': 'b912598052bca92d2c05195ad1b231d5'}\n",
      "                                                    0\n",
      "units                                              20\n",
      "learning_rate                                    0.01\n",
      "dropouts                                          0.2\n",
      "activation                                    sigmoid\n",
      "kernel_ini                             glorot_uniform\n",
      "tuner/epochs                                       30\n",
      "tuner/initial_epoch                                 6\n",
      "tuner/bracket                                       2\n",
      "tuner/round                                         2\n",
      "tuner/trial_id       b912598052bca92d2c05195ad1b231d5\n",
      "Tuning_time                                   796.436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 0</th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Class 3</th>\n",
       "      <th>Class 4</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>G-mean</th>\n",
       "      <th>Avg_Pfm</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP-W-1</th>\n",
       "      <td>0.633870</td>\n",
       "      <td>0.080851</td>\n",
       "      <td>0.106200</td>\n",
       "      <td>0.203145</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.545780</td>\n",
       "      <td>0.631388</td>\n",
       "      <td>0.244335</td>\n",
       "      <td>0.473834</td>\n",
       "      <td>6.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-W-2</th>\n",
       "      <td>0.547542</td>\n",
       "      <td>0.403232</td>\n",
       "      <td>0.108189</td>\n",
       "      <td>0.312579</td>\n",
       "      <td>0.734513</td>\n",
       "      <td>0.509422</td>\n",
       "      <td>0.702490</td>\n",
       "      <td>0.353039</td>\n",
       "      <td>0.521650</td>\n",
       "      <td>10.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-W-3</th>\n",
       "      <td>0.616168</td>\n",
       "      <td>0.216190</td>\n",
       "      <td>0.212399</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.802360</td>\n",
       "      <td>0.549086</td>\n",
       "      <td>0.652409</td>\n",
       "      <td>0.193501</td>\n",
       "      <td>0.464998</td>\n",
       "      <td>6.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-1</th>\n",
       "      <td>0.527121</td>\n",
       "      <td>0.330925</td>\n",
       "      <td>0.226876</td>\n",
       "      <td>0.348428</td>\n",
       "      <td>0.702065</td>\n",
       "      <td>0.490483</td>\n",
       "      <td>0.708612</td>\n",
       "      <td>0.395534</td>\n",
       "      <td>0.531543</td>\n",
       "      <td>301.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-2</th>\n",
       "      <td>0.533398</td>\n",
       "      <td>0.382140</td>\n",
       "      <td>0.166538</td>\n",
       "      <td>0.369182</td>\n",
       "      <td>0.696165</td>\n",
       "      <td>0.498531</td>\n",
       "      <td>0.714079</td>\n",
       "      <td>0.387390</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>301.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-3</th>\n",
       "      <td>0.563743</td>\n",
       "      <td>0.387560</td>\n",
       "      <td>0.121339</td>\n",
       "      <td>0.376730</td>\n",
       "      <td>0.693215</td>\n",
       "      <td>0.522340</td>\n",
       "      <td>0.716389</td>\n",
       "      <td>0.369883</td>\n",
       "      <td>0.536204</td>\n",
       "      <td>301.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-4</th>\n",
       "      <td>0.536906</td>\n",
       "      <td>0.398399</td>\n",
       "      <td>0.128191</td>\n",
       "      <td>0.282390</td>\n",
       "      <td>0.755162</td>\n",
       "      <td>0.500763</td>\n",
       "      <td>0.707498</td>\n",
       "      <td>0.357596</td>\n",
       "      <td>0.521952</td>\n",
       "      <td>301.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-5</th>\n",
       "      <td>0.558027</td>\n",
       "      <td>0.284591</td>\n",
       "      <td>0.239584</td>\n",
       "      <td>0.354717</td>\n",
       "      <td>0.710914</td>\n",
       "      <td>0.511949</td>\n",
       "      <td>0.712649</td>\n",
       "      <td>0.394827</td>\n",
       "      <td>0.539808</td>\n",
       "      <td>301.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-1</th>\n",
       "      <td>0.514119</td>\n",
       "      <td>0.421785</td>\n",
       "      <td>0.153387</td>\n",
       "      <td>0.408176</td>\n",
       "      <td>0.634218</td>\n",
       "      <td>0.486309</td>\n",
       "      <td>0.718895</td>\n",
       "      <td>0.386372</td>\n",
       "      <td>0.530525</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-2</th>\n",
       "      <td>0.496846</td>\n",
       "      <td>0.393321</td>\n",
       "      <td>0.216488</td>\n",
       "      <td>0.392453</td>\n",
       "      <td>0.616519</td>\n",
       "      <td>0.471670</td>\n",
       "      <td>0.714047</td>\n",
       "      <td>0.399970</td>\n",
       "      <td>0.528562</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-3</th>\n",
       "      <td>0.541221</td>\n",
       "      <td>0.441656</td>\n",
       "      <td>0.117030</td>\n",
       "      <td>0.379874</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>0.509101</td>\n",
       "      <td>0.715167</td>\n",
       "      <td>0.368239</td>\n",
       "      <td>0.530836</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-4</th>\n",
       "      <td>0.505772</td>\n",
       "      <td>0.380432</td>\n",
       "      <td>0.188087</td>\n",
       "      <td>0.404403</td>\n",
       "      <td>0.640118</td>\n",
       "      <td>0.476518</td>\n",
       "      <td>0.707883</td>\n",
       "      <td>0.392946</td>\n",
       "      <td>0.525782</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-5</th>\n",
       "      <td>0.564752</td>\n",
       "      <td>0.350747</td>\n",
       "      <td>0.175931</td>\n",
       "      <td>0.279245</td>\n",
       "      <td>0.740413</td>\n",
       "      <td>0.521082</td>\n",
       "      <td>0.714518</td>\n",
       "      <td>0.372847</td>\n",
       "      <td>0.536149</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
       "MLP-W-1         0.633870  0.080851  0.106200  0.203145  0.787611  0.545780   \n",
       "MLP-W-2         0.547542  0.403232  0.108189  0.312579  0.734513  0.509422   \n",
       "MLP-W-3         0.616168  0.216190  0.212399  0.011950  0.802360  0.549086   \n",
       "MLP-accuracy-1  0.527121  0.330925  0.226876  0.348428  0.702065  0.490483   \n",
       "MLP-accuracy-2  0.533398  0.382140  0.166538  0.369182  0.696165  0.498531   \n",
       "MLP-accuracy-3  0.563743  0.387560  0.121339  0.376730  0.693215  0.522340   \n",
       "MLP-accuracy-4  0.536906  0.398399  0.128191  0.282390  0.755162  0.500763   \n",
       "MLP-accuracy-5  0.558027  0.284591  0.239584  0.354717  0.710914  0.511949   \n",
       "MLP-accuracy-1  0.514119  0.421785  0.153387  0.408176  0.634218  0.486309   \n",
       "MLP-accuracy-2  0.496846  0.393321  0.216488  0.392453  0.616519  0.471670   \n",
       "MLP-accuracy-3  0.541221  0.441656  0.117030  0.379874  0.637168  0.509101   \n",
       "MLP-accuracy-4  0.505772  0.380432  0.188087  0.404403  0.640118  0.476518   \n",
       "MLP-accuracy-5  0.564752  0.350747  0.175931  0.279245  0.740413  0.521082   \n",
       "\n",
       "                     AUC    G-mean   Avg_Pfm  Training Time  \n",
       "MLP-W-1         0.631388  0.244335  0.473834          6.282  \n",
       "MLP-W-2         0.702490  0.353039  0.521650         10.828  \n",
       "MLP-W-3         0.652409  0.193501  0.464998          6.165  \n",
       "MLP-accuracy-1  0.708612  0.395534  0.531543        301.527  \n",
       "MLP-accuracy-2  0.714079  0.387390  0.533333        301.527  \n",
       "MLP-accuracy-3  0.716389  0.369883  0.536204        301.527  \n",
       "MLP-accuracy-4  0.707498  0.357596  0.521952        301.527  \n",
       "MLP-accuracy-5  0.712649  0.394827  0.539808        301.527  \n",
       "MLP-accuracy-1  0.718895  0.386372  0.530525        796.436  \n",
       "MLP-accuracy-2  0.714047  0.399970  0.528562        796.436  \n",
       "MLP-accuracy-3  0.715167  0.368239  0.530836        796.436  \n",
       "MLP-accuracy-4  0.707883  0.392946  0.525782        796.436  \n",
       "MLP-accuracy-5  0.714518  0.372847  0.536149        796.436  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bps = pd.DataFrame()\n",
    "obj = 'accuracy'\n",
    "tuner = Hyperband(build_model,\n",
    "                     objective = obj, \n",
    "                     max_epochs = MAX_EPOCHS,\n",
    "                     factor = FACTOR,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'val_'+ obj+'_'+time.ctime())\n",
    "tuner.search(X_res, y_res,\n",
    "             epochs=MAX_EPOCHS,batch_size=2048,\n",
    "             verbose=0,\n",
    "             callbacks=[early_stops(obj)],\n",
    "             validation_data=(X_val, y_val))\n",
    "end = time.time()\n",
    "\n",
    "print('Tuning time is %.2f' % (end-start))\n",
    "print(tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values)\n",
    "bp = pd.Series(tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values,name=obj)\n",
    "bp = bp.append(pd.Series(end-start,index=['Tuning_time']))\n",
    "bps = pd.concat((bps,bp),axis=1)\n",
    "models = tuner.get_best_models(num_models=FACTOR)\n",
    "for i in range(FACTOR):\n",
    "    Y_pred = models[i].predict(X_test)\n",
    "    rsts = rsts.append(get_accs(y_test.values,Y_pred,end-start,'MLP-'+obj+'-'+str(i+1)))\n",
    "print(bps)\n",
    "print(rsts.iloc[:,5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0\n",
      "units                                              20\n",
      "learning_rate                                    0.01\n",
      "dropouts                                          0.2\n",
      "activation                                    sigmoid\n",
      "kernel_ini                             glorot_uniform\n",
      "tuner/epochs                                       30\n",
      "tuner/initial_epoch                                 6\n",
      "tuner/bracket                                       2\n",
      "tuner/round                                         2\n",
      "tuner/trial_id       b912598052bca92d2c05195ad1b231d5\n",
      "Tuning_time                                   796.436\n",
      "                Accuracy       AUC    G-mean   Avg_Pfm  Training Time\n",
      "MLP-W-1         0.545780  0.631388  0.244335  0.473834          6.282\n",
      "MLP-W-2         0.509422  0.702490  0.353039  0.521650         10.828\n",
      "MLP-W-3         0.549086  0.652409  0.193501  0.464998          6.165\n",
      "MLP-accuracy-1  0.490483  0.708612  0.395534  0.531543        301.527\n",
      "MLP-accuracy-2  0.498531  0.714079  0.387390  0.533333        301.527\n",
      "MLP-accuracy-3  0.522340  0.716389  0.369883  0.536204        301.527\n",
      "MLP-accuracy-4  0.500763  0.707498  0.357596  0.521952        301.527\n",
      "MLP-accuracy-5  0.511949  0.712649  0.394827  0.539808        301.527\n",
      "MLP-accuracy-1  0.486309  0.718895  0.386372  0.530525        796.436\n",
      "MLP-accuracy-2  0.471670  0.714047  0.399970  0.528562        796.436\n",
      "MLP-accuracy-3  0.509101  0.715167  0.368239  0.530836        796.436\n",
      "MLP-accuracy-4  0.476518  0.707883  0.392946  0.525782        796.436\n",
      "MLP-accuracy-5  0.521082  0.714518  0.372847  0.536149        796.436\n",
      "MLP-accuracy-1  0.486309  0.718895  0.386372  0.530525        796.436\n",
      "MLP-accuracy-2  0.471670  0.714047  0.399970  0.528562        796.436\n",
      "MLP-accuracy-3  0.509101  0.715167  0.368239  0.530836        796.436\n",
      "MLP-accuracy-4  0.476518  0.707883  0.392946  0.525782        796.436\n",
      "MLP-accuracy-5  0.521082  0.714518  0.372847  0.536149        796.436\n"
     ]
    }
   ],
   "source": [
    "for i in range(FACTOR):\n",
    "    Y_pred = models[i].predict(X_test)\n",
    "    rsts = rsts.append(get_accs(y_test.values,Y_pred,end-start,'MLP-'+obj+'-'+str(i+1)))\n",
    "print(bps)\n",
    "print(rsts.iloc[:,5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestm = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyb_sam(random=12):\n",
    "    start = time.time()\n",
    "    res = RandomUnderSampler(random_state = random, sampling_strategy={0: y_dict[1]})\n",
    "    print('under sampling ...')\n",
    "    X_sam, y_sam = res.fit_resample(X_train, y_train)\n",
    "    print(Counter(y_sam))\n",
    "    print('over sampling #2 ...')\n",
    "    res = SMOTE(random_state = random,sampling_strategy='not majority')\n",
    "    X_sam, y_sam = res.fit_resample(X_sam, y_sam)\n",
    "    end = time.time()\n",
    "    res_time = end-start\n",
    "    print('Resampling time is %.2f' % res_time)\n",
    "    return X_sam, y_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under sampling ...\n",
      "Counter({0: 65541, 1: 65541, 2: 28954, 3: 5089, 4: 1086})\n",
      "over sampling #2 ...\n",
      "Resampling time is 72.78\n"
     ]
    }
   ],
   "source": [
    "X_res2, y_res2 = hyb_sam(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 10, 96, 16, 63])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(4)\n",
    "rs = np.random.choice(range(100), 5, replace=False)\n",
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under sampling ...\n",
      "Counter({0: 65541, 1: 65541, 2: 28954, 3: 5089, 4: 1086})\n",
      "over sampling #2 ...\n",
      "Resampling time is 72.07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Retraining Done!\n",
      "under sampling ...\n",
      "Counter({0: 65541, 1: 65541, 2: 28954, 3: 5089, 4: 1086})\n",
      "over sampling #2 ...\n",
      "Resampling time is 70.41\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Retraining Done!\n",
      "under sampling ...\n",
      "Counter({0: 65541, 1: 65541, 2: 28954, 3: 5089, 4: 1086})\n",
      "over sampling #2 ...\n",
      "Resampling time is 73.28\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Retraining Done!\n",
      "under sampling ...\n",
      "Counter({0: 65541, 1: 65541, 2: 28954, 3: 5089, 4: 1086})\n",
      "over sampling #2 ...\n",
      "Resampling time is 70.86\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Retraining Done!\n",
      "under sampling ...\n",
      "Counter({0: 65541, 1: 65541, 2: 28954, 3: 5089, 4: 1086})\n",
      "over sampling #2 ...\n",
      "Resampling time is 72.08\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Retraining Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>G-mean</th>\n",
       "      <th>Avg_Pfm</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP-W-1</th>\n",
       "      <td>0.545780</td>\n",
       "      <td>0.631388</td>\n",
       "      <td>0.244335</td>\n",
       "      <td>0.473834</td>\n",
       "      <td>6.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-W-2</th>\n",
       "      <td>0.509422</td>\n",
       "      <td>0.702490</td>\n",
       "      <td>0.353039</td>\n",
       "      <td>0.521650</td>\n",
       "      <td>10.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-W-3</th>\n",
       "      <td>0.549086</td>\n",
       "      <td>0.652409</td>\n",
       "      <td>0.193501</td>\n",
       "      <td>0.464998</td>\n",
       "      <td>6.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-1</th>\n",
       "      <td>0.490483</td>\n",
       "      <td>0.708612</td>\n",
       "      <td>0.395534</td>\n",
       "      <td>0.531543</td>\n",
       "      <td>301.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-2</th>\n",
       "      <td>0.498531</td>\n",
       "      <td>0.714079</td>\n",
       "      <td>0.387390</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>301.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-3</th>\n",
       "      <td>0.522340</td>\n",
       "      <td>0.716389</td>\n",
       "      <td>0.369883</td>\n",
       "      <td>0.536204</td>\n",
       "      <td>301.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-4</th>\n",
       "      <td>0.500763</td>\n",
       "      <td>0.707498</td>\n",
       "      <td>0.357596</td>\n",
       "      <td>0.521952</td>\n",
       "      <td>301.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-5</th>\n",
       "      <td>0.511949</td>\n",
       "      <td>0.712649</td>\n",
       "      <td>0.394827</td>\n",
       "      <td>0.539808</td>\n",
       "      <td>301.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-1</th>\n",
       "      <td>0.486309</td>\n",
       "      <td>0.718895</td>\n",
       "      <td>0.386372</td>\n",
       "      <td>0.530525</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-2</th>\n",
       "      <td>0.471670</td>\n",
       "      <td>0.714047</td>\n",
       "      <td>0.399970</td>\n",
       "      <td>0.528562</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-3</th>\n",
       "      <td>0.509101</td>\n",
       "      <td>0.715167</td>\n",
       "      <td>0.368239</td>\n",
       "      <td>0.530836</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-4</th>\n",
       "      <td>0.476518</td>\n",
       "      <td>0.707883</td>\n",
       "      <td>0.392946</td>\n",
       "      <td>0.525782</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-5</th>\n",
       "      <td>0.521082</td>\n",
       "      <td>0.714518</td>\n",
       "      <td>0.372847</td>\n",
       "      <td>0.536149</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-1</th>\n",
       "      <td>0.486309</td>\n",
       "      <td>0.718895</td>\n",
       "      <td>0.386372</td>\n",
       "      <td>0.530525</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-2</th>\n",
       "      <td>0.471670</td>\n",
       "      <td>0.714047</td>\n",
       "      <td>0.399970</td>\n",
       "      <td>0.528562</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-3</th>\n",
       "      <td>0.509101</td>\n",
       "      <td>0.715167</td>\n",
       "      <td>0.368239</td>\n",
       "      <td>0.530836</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-4</th>\n",
       "      <td>0.476518</td>\n",
       "      <td>0.707883</td>\n",
       "      <td>0.392946</td>\n",
       "      <td>0.525782</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-accuracy-5</th>\n",
       "      <td>0.521082</td>\n",
       "      <td>0.714518</td>\n",
       "      <td>0.372847</td>\n",
       "      <td>0.536149</td>\n",
       "      <td>796.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy-refit-21</th>\n",
       "      <td>0.518492</td>\n",
       "      <td>0.717937</td>\n",
       "      <td>0.385729</td>\n",
       "      <td>0.540720</td>\n",
       "      <td>73.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy-refit-11</th>\n",
       "      <td>0.509817</td>\n",
       "      <td>0.716919</td>\n",
       "      <td>0.398004</td>\n",
       "      <td>0.541580</td>\n",
       "      <td>73.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy-refit-97</th>\n",
       "      <td>0.506338</td>\n",
       "      <td>0.715822</td>\n",
       "      <td>0.391828</td>\n",
       "      <td>0.537996</td>\n",
       "      <td>73.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy-refit-17</th>\n",
       "      <td>0.506601</td>\n",
       "      <td>0.715646</td>\n",
       "      <td>0.380708</td>\n",
       "      <td>0.534318</td>\n",
       "      <td>73.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy-refit-64</th>\n",
       "      <td>0.524046</td>\n",
       "      <td>0.716758</td>\n",
       "      <td>0.395862</td>\n",
       "      <td>0.545555</td>\n",
       "      <td>73.087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy       AUC    G-mean   Avg_Pfm  Training Time\n",
       "MLP-W-1            0.545780  0.631388  0.244335  0.473834          6.282\n",
       "MLP-W-2            0.509422  0.702490  0.353039  0.521650         10.828\n",
       "MLP-W-3            0.549086  0.652409  0.193501  0.464998          6.165\n",
       "MLP-accuracy-1     0.490483  0.708612  0.395534  0.531543        301.527\n",
       "MLP-accuracy-2     0.498531  0.714079  0.387390  0.533333        301.527\n",
       "MLP-accuracy-3     0.522340  0.716389  0.369883  0.536204        301.527\n",
       "MLP-accuracy-4     0.500763  0.707498  0.357596  0.521952        301.527\n",
       "MLP-accuracy-5     0.511949  0.712649  0.394827  0.539808        301.527\n",
       "MLP-accuracy-1     0.486309  0.718895  0.386372  0.530525        796.436\n",
       "MLP-accuracy-2     0.471670  0.714047  0.399970  0.528562        796.436\n",
       "MLP-accuracy-3     0.509101  0.715167  0.368239  0.530836        796.436\n",
       "MLP-accuracy-4     0.476518  0.707883  0.392946  0.525782        796.436\n",
       "MLP-accuracy-5     0.521082  0.714518  0.372847  0.536149        796.436\n",
       "MLP-accuracy-1     0.486309  0.718895  0.386372  0.530525        796.436\n",
       "MLP-accuracy-2     0.471670  0.714047  0.399970  0.528562        796.436\n",
       "MLP-accuracy-3     0.509101  0.715167  0.368239  0.530836        796.436\n",
       "MLP-accuracy-4     0.476518  0.707883  0.392946  0.525782        796.436\n",
       "MLP-accuracy-5     0.521082  0.714518  0.372847  0.536149        796.436\n",
       "accuracy-refit-21  0.518492  0.717937  0.385729  0.540720         73.087\n",
       "accuracy-refit-11  0.509817  0.716919  0.398004  0.541580         73.087\n",
       "accuracy-refit-97  0.506338  0.715822  0.391828  0.537996         73.087\n",
       "accuracy-refit-17  0.506601  0.715646  0.380708  0.534318         73.087\n",
       "accuracy-refit-64  0.524046  0.716758  0.395862  0.545555         73.087"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsts\n",
    "for i in rs:\n",
    "    bestm = models[0]\n",
    "    X_res2, y_res2 = hyb_sam(i)\n",
    "    bestm.fit(X_res2, y_res2,\n",
    "                            callbacks=[early_stops('accuracy')],\n",
    "                            validation_data=(X_val,y_val),\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            verbose=VERBOSE, epochs=EPOCH\n",
    "                           )\n",
    "    print('Retraining Done!')\n",
    "    Y_pred = bestm.predict(X_test)\n",
    "    rsts = rsts.append(get_accs(y_test.values,Y_pred,end-start,obj+'-refit-'+str(i+1)))\n",
    "rsts.iloc[:,5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsts.to_csv('Extra fiting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
      "MLP-accuracy-5  0.548274  0.349087  0.199912  0.394969  0.628319  0.509064   \n",
      "\n",
      "                    AUC    G-mean  Avg_Pfm  Training Time  \n",
      "MLP-accuracy-5  0.72071  0.394006  0.54126         73.087  \n"
     ]
    }
   ],
   "source": [
    "Y_pred = bestm.predict(X_test)\n",
    "print(get_accs(y_test.values,Y_pred,end-start,'MLP-'+obj+'-'+str(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "VCA_2.1_MLP_earlystopping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
