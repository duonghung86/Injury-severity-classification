{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/duonghung86/Injury-severity-classification/blob/main/VCA_2_1_MLP_earlystopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bo-3JT-1cl14",
    "outputId": "c710009f-72c5-44ef-9e68-7b27f7c8d34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 270.0 gigabytes of available RAM\n",
      "\n",
      "Current system-wide CPU utilization %:  50.0\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory,cpu_percent\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "print('Current system-wide CPU utilization %: ',cpu_percent())\n",
    "#Remove all warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ond2r97pZvoF",
    "outputId": "090a81b4-6b1f-46d8-abb5-725257820a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "from collections import Counter\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler # Standardization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Machine learning algos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Imblearn\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler,BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,NearMiss,EditedNearestNeighbours\n",
    "\n",
    "# Grid search\n",
    "from kerastuner.tuners import RandomSearch,Hyperband,BayesianOptimization\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import feature_column  # for data wrangling\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy,CategoricalCrossentropy\n",
    "from tensorflow.keras.layers import Dense,Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy,CategoricalAccuracy\n",
    "from tensorflow_addons.metrics import CohenKappa,F1Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMFYXIMkFSak",
    "outputId": "d80430a7-b93b-421a-a2d9-3b1cbf3e5ba5"
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/duonghung86/Injury-severity-classification/blob/main/Prepared%20Texas%202019.zip?raw=true' \n",
    "data_path = tf.keras.utils.get_file(origin=url, fname=url.split('/')[-1].split('?')[0], extract=True)\n",
    "data_path = data_path.replace('%20',' ').replace('.zip','.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "UPLNCpWjZvoG",
    "outputId": "7d652183-53ce-4328-aada-ea393cc2efce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(949856, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prsn_Injry_Sev</th>\n",
       "      <th>Prsn_Age</th>\n",
       "      <th>Prsn_Gndr</th>\n",
       "      <th>Wthr_Cond</th>\n",
       "      <th>Light_Cond</th>\n",
       "      <th>Surf_Cond</th>\n",
       "      <th>Veh_Body_Styl</th>\n",
       "      <th>Prsn_Rest</th>\n",
       "      <th>Prsn_Drg_Rslt</th>\n",
       "      <th>Harm_Evnt</th>\n",
       "      <th>Rural</th>\n",
       "      <th>Crash_Speed_Limit</th>\n",
       "      <th>Road_Algn</th>\n",
       "      <th>Veh_Mod_Year</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Crash_season</th>\n",
       "      <th>Part_of_day</th>\n",
       "      <th>Collsn_type</th>\n",
       "      <th>Collsn_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>MALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PASSENGER CAR, 2-DOOR</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>STRAIGHT, LEVEL</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>ONE STRAIGHT-ONE LEFT TURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>MALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PASSENGER CAR, 2-DOOR</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>STRAIGHT, LEVEL</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>ONE STRAIGHT-ONE LEFT TURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PICKUP</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>CURVE, LEVEL</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>BOTH LEFT TURN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prsn_Injry_Sev  Prsn_Age Prsn_Gndr Wthr_Cond Light_Cond Surf_Cond  \\\n",
       "0               0        26      MALE     CLEAR   DAYLIGHT       DRY   \n",
       "1               0        52      MALE     CLEAR   DAYLIGHT       DRY   \n",
       "2               0        27    FEMALE     CLEAR   DAYLIGHT       DRY   \n",
       "\n",
       "           Veh_Body_Styl            Prsn_Rest   Prsn_Drg_Rslt  \\\n",
       "0  PASSENGER CAR, 2-DOOR  SHOULDER & LAP BELT  Not Applicable   \n",
       "1  PASSENGER CAR, 2-DOOR  SHOULDER & LAP BELT  Not Applicable   \n",
       "2                 PICKUP  SHOULDER & LAP BELT  Not Applicable   \n",
       "\n",
       "                    Harm_Evnt  Rural  Crash_Speed_Limit        Road_Algn  \\\n",
       "0  MOTOR VEHICLE IN TRANSPORT      0                 -1  STRAIGHT, LEVEL   \n",
       "1  MOTOR VEHICLE IN TRANSPORT      0                 -1  STRAIGHT, LEVEL   \n",
       "2  MOTOR VEHICLE IN TRANSPORT      1                 -1     CURVE, LEVEL   \n",
       "\n",
       "   Veh_Mod_Year  Weekend  Crash_season  Part_of_day     Collsn_type  \\\n",
       "0            33        1             3            3  SAME DIRECTION   \n",
       "1            19        1             3            3  SAME DIRECTION   \n",
       "2            16        1             3            4  SAME DIRECTION   \n",
       "\n",
       "                  Collsn_name  \n",
       "0  ONE STRAIGHT-ONE LEFT TURN  \n",
       "1  ONE STRAIGHT-ONE LEFT TURN  \n",
       "2              BOTH LEFT TURN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(data_path)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1CDPbDPYZvoH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949856, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's just use 80% of the total dataset\n",
    "#df, _ = train_test_split(df, test_size=0.9,stratify = df['Prsn_Injry_Sev'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEKbv3R9ZvoH",
    "outputId": "93f16610-1110-4ffe-9c66-f4dea88ae652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All target values:\n",
      "0    792558\n",
      "1    102409\n",
      "2     45242\n",
      "3      7951\n",
      "4      1696\n",
      "Name: Prsn_Injry_Sev, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df['Prsn_Injry_Sev']\n",
    "print('All target values:')\n",
    "print(y.value_counts())\n",
    "X = df.drop(columns=['Prsn_Injry_Sev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUDtEBDsZvoI",
    "outputId": "b311b931-acd8-453a-95f9-b54c0b572d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical variables are  ['Prsn_Age', 'Rural', 'Crash_Speed_Limit', 'Veh_Mod_Year', 'Weekend', 'Crash_season', 'Part_of_day']\n",
      "Categorical variables that have at most 5 categories are  ['Prsn_Gndr', 'Prsn_Drg_Rslt', 'Collsn_type']\n",
      "Categorical variables that have more than 5 categories are  ['Wthr_Cond', 'Light_Cond', 'Surf_Cond', 'Veh_Body_Styl', 'Prsn_Rest', 'Harm_Evnt', 'Road_Algn', 'Collsn_name']\n",
      "WARNING:tensorflow:From /project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "New shape of the input data set: (949856, 59)\n"
     ]
    }
   ],
   "source": [
    "# %% Data wrangling -------------\n",
    "# Classify variable type\n",
    "emb_vars, ind_vars, num_vars = [], [], []\n",
    "for var in X.columns:\n",
    "    if X[var].dtypes == 'O':\n",
    "        if len(X[var].unique()) > 5:\n",
    "            emb_vars.append(var)\n",
    "        else:\n",
    "            ind_vars.append(var)\n",
    "    else:\n",
    "        num_vars.append(var)\n",
    "print('Numerical variables are ', num_vars)\n",
    "print('Categorical variables that have at most 5 categories are ', ind_vars)\n",
    "print('Categorical variables that have more than 5 categories are ', emb_vars)\n",
    "\n",
    "# Create feature columns\n",
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in num_vars:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "# bucketized cols\n",
    "# age = feature_column.numeric_column('Prsn_Age')\n",
    "# age_buckets = feature_column.bucketized_column(age, boundaries=[16, 22, 35, 55, 65])\n",
    "# feature_columns.append(age_buckets)\n",
    "# indicator_columns\n",
    "for col_name in ind_vars:\n",
    "    categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, X[col_name].unique())\n",
    "    indicator_column = feature_column.indicator_column(categorical_column)\n",
    "    feature_columns.append(indicator_column)\n",
    "# embedding columns\n",
    "for col_name in emb_vars:\n",
    "    emb_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, X[col_name].unique())\n",
    "    col_embedding = feature_column.embedding_column(emb_column, dimension=5)\n",
    "    feature_columns.append(col_embedding)\n",
    "\n",
    "# Convert all setup into new dataset\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "X = feature_layer(dict(X)).numpy()\n",
    "print('New shape of the input data set:',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EiMyeEfZvoJ",
    "outputId": "a73f13c7-932e-49e5-bb80-6c9d506ad140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (607907, 59)\n",
      "Validation features shape: (151977, 59)\n",
      "Test features shape: (189972, 59)\n"
     ]
    }
   ],
   "source": [
    "# %% Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=48)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=48)\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation features shape:', X_val.shape)\n",
    "print('Test features shape:', X_test.shape)\n",
    "\n",
    "# %% standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ds5G6Pjhes9"
   },
   "source": [
    "# ALL mini functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Metrics\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,accuracy_score\n",
    "\n",
    "# %% Function to compare the prediction and true labels\n",
    "def get_accs(label, pred_proba, tr_time=0,index=None):\n",
    "    prediction = pred_proba.argmax(axis=1)\n",
    "    cm = confusion_matrix(label, prediction)\n",
    "    length = cm.shape[0]\n",
    "    num_cases = len(label)\n",
    "    # global accuracy\n",
    "    glb_acc = np.trace(cm) / len(label)\n",
    "    ind_accs = cm / np.sum(cm, axis=1)[:, np.newaxis]\n",
    "    accs = [ind_accs[i, i] for i in range(length)]\n",
    "    cols = ['Class {}'.format(i) for i in range(length)]\n",
    "    # Global accuracy\n",
    "    accs.append(glb_acc)\n",
    "    # AUC\n",
    "    accs.append(roc_auc_score(label, pred_proba,multi_class='ovr'))\n",
    "    # G-mean\n",
    "    accs.append(geometric_mean_score(label, prediction, correction=0.001))\n",
    "    # Average perf\n",
    "    accs.append(np.mean(accs[-3:]))\n",
    "    # Training time\n",
    "    accs.append(np.round(tr_time,3))\n",
    "    cols = cols + ['Accuracy','AUC','G-mean','Avg_Pfm','Training Time']\n",
    "\n",
    "    out = np.array(accs).reshape(1, len(accs))\n",
    "    return pd.DataFrame(out, columns=cols,index=[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with class weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff6Y5pBDhsXm"
   },
   "source": [
    "# MLP functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmzSlMdDZvoK",
    "outputId": "3e186bc5-a34c-42fc-90a7-98f73ea8d376"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.23969347661941065,\n",
       " 1: 1.8550434079431195,\n",
       " 2: 4.199122746425364,\n",
       " 3: 23.891019846728238,\n",
       " 4: 111.95340699815839}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add weights\n",
    "weights = len(y_train) / (5 * np.bincount(y_train))\n",
    "cls_wgt = dict(zip(np.arange(5), weights))\n",
    "cls_wgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "w5IRiyFuZvoK"
   },
   "outputs": [],
   "source": [
    "def early_stops(metric_name):\n",
    "    es = EarlyStopping(monitor='val_'+ metric_name,\n",
    "                   verbose=1, patience=10, mode='max',\n",
    "                   restore_best_weights=True)\n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 2048\n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [SparseCategoricalAccuracy(name='accuracy'),\n",
    "           CohenKappa(name='kappa',num_classes=5,sparse_labels=True),\n",
    "           F1Score(name='f1_micro', num_classes=5,average=\"micro\",threshold=0.5),\n",
    "          ]\n",
    "def create_mlp():\n",
    "    MLP = Sequential([Dense(10,\n",
    "                           activation='relu',\n",
    "                           input_dim=X_train.shape[1],\n",
    "                           ),\n",
    "                      Dropout(0.5),\n",
    "                      Dense(5, activation='softmax')])\n",
    "    MLP.compile(optimizer='adam',\n",
    "                loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=METRICS\n",
    "               )\n",
    "    return MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Resampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under sampling ...\n",
      "Counter({0: 65541, 1: 65541, 2: 28954, 3: 5089, 4: 1086})\n",
      "over sampling #2 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Counter({0: 65541, 1: 65541, 2: 65541, 3: 65541, 4: 65541}),\n",
       " 78.57090425491333)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dict = Counter(y_train)\n",
    "\n",
    "start = time.time()\n",
    "res = RandomUnderSampler(random_state = 54, sampling_strategy={0: y_dict[1]})\n",
    "print('under sampling ...')\n",
    "X_res, y_res = res.fit_resample(X_train, y_train)\n",
    "\n",
    "res = SMOTE(random_state = 34,sampling_strategy='not majority')\n",
    "print(Counter(y_res))\n",
    "print('over sampling #2 ...')\n",
    "X_res, y_res = res.fit_resample(X_res, y_res)\n",
    "end = time.time()\n",
    "res_time = end-start\n",
    "Counter(y_res),res_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with Hybrid Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsts = pd.DataFrame()\n",
    "for i in range(3):\n",
    "    model = create_mlp()\n",
    "    start = time.time()\n",
    "    monitor = model.fit(X_res, y_res,\n",
    "                        callbacks=[early_stops('accuracy')],\n",
    "                        validation_data=(X_val,y_val),\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        verbose=VERBOSE, epochs=EPOCH\n",
    "                       )\n",
    "    end = time.time()\n",
    "    # use the model to make predictions with the test data\n",
    "    Y_pred = model.predict(X_test)\n",
    "    rsts = rsts.append(get_accs(y_test.values,Y_pred,end-start,'MLP-HS#'+str(i+1)))\n",
    "print(rsts.iloc[:,5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up grid search\n",
    "\n",
    "We will investigates the following parameters:\n",
    "\n",
    "- Initial weights\n",
    "- Activation function\n",
    "- Number of nodes\n",
    "- Dropout rate\n",
    "- Early Stop\n",
    "- Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    hp_units = hp.Int('units', min_value=5, max_value=15, step=5)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "    hp_dos = hp.Float('dropouts',min_value=0.2, max_value=0.5, step=0.1)\n",
    "    hp_acts = hp.Choice('activation', values = ['relu','sigmoid','tanh','selu'])\n",
    "    keins = ['uniform', 'lecun_uniform', 'normal', 'zeros', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "    hp_keins = hp.Choice('kernel_ini', values = keins) \n",
    "    model = Sequential([Dense(hp_units,\n",
    "                           activation=hp_acts,\n",
    "                           input_dim=X_train.shape[1],\n",
    "                            kernel_initializer= hp_keins \n",
    "                           ),\n",
    "                      Dropout(hp_dos),\n",
    "                      Dense(5, activation='softmax')])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=METRICS\n",
    "               )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metr = ['loss','accuracy','kappa','f1_micro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 5\n",
    "FACTOR = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Tuning time is 26.98\n",
      "{'units': 15, 'learning_rate': 0.01, 'dropouts': 0.4000000000000001, 'activation': 'selu', 'kernel_ini': 'uniform', 'tuner/epochs': 5, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
      "Empty DataFrame\n",
      "Columns: [Class 0, Class 1, Class 2, Class 3, Class 4, Accuracy, AUC, G-mean, Avg_Pfm, Training Time]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Class 0, Class 1, Class 2, Class 3, Class 4, Accuracy, AUC, G-mean, Avg_Pfm, Training Time]\n",
      "Index: []\n",
      "             Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
      "MLP-loss-3  0.542035  0.391173  0.142999  0.271698  0.725664  0.504827   \n",
      "\n",
      "                 AUC    G-mean   Avg_Pfm  Training Time  \n",
      "MLP-loss-3  0.696171  0.359178  0.520059         26.979  \n",
      "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Tuning time is 27.11\n",
      "{'units': 15, 'learning_rate': 0.01, 'dropouts': 0.2, 'activation': 'sigmoid', 'kernel_ini': 'glorot_normal', 'tuner/epochs': 5, 'tuner/initial_epoch': 2, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '26e69834bde1768efbb75574f11b565d'}\n",
      "                 Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
      "MLP-loss-3      0.542035  0.391173  0.142999  0.271698  0.725664  0.504827   \n",
      "MLP-accuracy-1  0.549132  0.384679  0.150182  0.316352  0.716814  0.510749   \n",
      "\n",
      "                     AUC    G-mean   Avg_Pfm  Training Time  \n",
      "MLP-loss-3      0.696171  0.359178  0.520059         26.979  \n",
      "MLP-accuracy-1  0.715896  0.372730  0.533125         27.110  \n",
      "                 Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
      "MLP-loss-3      0.542035  0.391173  0.142999  0.271698  0.725664  0.504827   \n",
      "MLP-accuracy-1  0.549132  0.384679  0.150182  0.316352  0.716814  0.510749   \n",
      "MLP-accuracy-2  0.511595  0.400156  0.168085  0.316352  0.716814  0.481950   \n",
      "\n",
      "                     AUC    G-mean   Avg_Pfm  Training Time  \n",
      "MLP-loss-3      0.696171  0.359178  0.520059         26.979  \n",
      "MLP-accuracy-1  0.715896  0.372730  0.533125         27.110  \n",
      "MLP-accuracy-2  0.710113  0.378837  0.523633         27.110  \n",
      "                 Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
      "MLP-loss-3      0.542035  0.391173  0.142999  0.271698  0.725664  0.504827   \n",
      "MLP-accuracy-1  0.549132  0.384679  0.150182  0.316352  0.716814  0.510749   \n",
      "MLP-accuracy-2  0.511595  0.400156  0.168085  0.316352  0.716814  0.481950   \n",
      "MLP-accuracy-3  0.510592  0.367835  0.208089  0.258491  0.755162  0.479118   \n",
      "\n",
      "                     AUC    G-mean   Avg_Pfm  Training Time  \n",
      "MLP-loss-3      0.696171  0.359178  0.520059         26.979  \n",
      "MLP-accuracy-1  0.715896  0.372730  0.533125         27.110  \n",
      "MLP-accuracy-2  0.710113  0.378837  0.523633         27.110  \n",
      "MLP-accuracy-3  0.700249  0.377131  0.518833         27.110  \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Tuning time is 27.64\n",
      "{'units': 5, 'learning_rate': 0.01, 'dropouts': 0.30000000000000004, 'activation': 'selu', 'kernel_ini': 'lecun_uniform', 'tuner/epochs': 2, 'tuner/initial_epoch': 0, 'tuner/bracket': 1, 'tuner/round': 0}\n",
      "                 Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
      "MLP-loss-3      0.542035  0.391173  0.142999  0.271698  0.725664  0.504827   \n",
      "MLP-accuracy-1  0.549132  0.384679  0.150182  0.316352  0.716814  0.510749   \n",
      "MLP-accuracy-2  0.511595  0.400156  0.168085  0.316352  0.716814  0.481950   \n",
      "MLP-accuracy-3  0.510592  0.367835  0.208089  0.258491  0.755162  0.479118   \n",
      "MLP-kappa-1     0.550968  0.346206  0.204774  0.266667  0.728614  0.510338   \n",
      "\n",
      "                     AUC    G-mean   Avg_Pfm  Training Time  \n",
      "MLP-loss-3      0.696171  0.359178  0.520059         26.979  \n",
      "MLP-accuracy-1  0.715896  0.372730  0.533125         27.110  \n",
      "MLP-accuracy-2  0.710113  0.378837  0.523633         27.110  \n",
      "MLP-accuracy-3  0.700249  0.377131  0.518833         27.110  \n",
      "MLP-kappa-1     0.699859  0.376739  0.528979         27.639  \n",
      "                 Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
      "MLP-loss-3      0.542035  0.391173  0.142999  0.271698  0.725664  0.504827   \n",
      "MLP-accuracy-1  0.549132  0.384679  0.150182  0.316352  0.716814  0.510749   \n",
      "MLP-accuracy-2  0.511595  0.400156  0.168085  0.316352  0.716814  0.481950   \n",
      "MLP-accuracy-3  0.510592  0.367835  0.208089  0.258491  0.755162  0.479118   \n",
      "MLP-kappa-1     0.550968  0.346206  0.204774  0.266667  0.728614  0.510338   \n",
      "MLP-kappa-2     0.533524  0.390880  0.165101  0.256604  0.758112  0.498679   \n",
      "\n",
      "                     AUC    G-mean   Avg_Pfm  Training Time  \n",
      "MLP-loss-3      0.696171  0.359178  0.520059         26.979  \n",
      "MLP-accuracy-1  0.715896  0.372730  0.533125         27.110  \n",
      "MLP-accuracy-2  0.710113  0.378837  0.523633         27.110  \n",
      "MLP-accuracy-3  0.700249  0.377131  0.518833         27.110  \n",
      "MLP-kappa-1     0.699859  0.376739  0.528979         27.639  \n",
      "MLP-kappa-2     0.688947  0.367442  0.518356         27.639  \n",
      "                 Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
      "MLP-loss-3      0.542035  0.391173  0.142999  0.271698  0.725664  0.504827   \n",
      "MLP-accuracy-1  0.549132  0.384679  0.150182  0.316352  0.716814  0.510749   \n",
      "MLP-accuracy-2  0.511595  0.400156  0.168085  0.316352  0.716814  0.481950   \n",
      "MLP-accuracy-3  0.510592  0.367835  0.208089  0.258491  0.755162  0.479118   \n",
      "MLP-kappa-1     0.550968  0.346206  0.204774  0.266667  0.728614  0.510338   \n",
      "MLP-kappa-2     0.533524  0.390880  0.165101  0.256604  0.758112  0.498679   \n",
      "MLP-kappa-3     0.542035  0.335612  0.225218  0.288679  0.728614  0.502900   \n",
      "\n",
      "                     AUC    G-mean   Avg_Pfm  Training Time  \n",
      "MLP-loss-3      0.696171  0.359178  0.520059         26.979  \n",
      "MLP-accuracy-1  0.715896  0.372730  0.533125         27.110  \n",
      "MLP-accuracy-2  0.710113  0.378837  0.523633         27.110  \n",
      "MLP-accuracy-3  0.700249  0.377131  0.518833         27.110  \n",
      "MLP-kappa-1     0.699859  0.376739  0.528979         27.639  \n",
      "MLP-kappa-2     0.688947  0.367442  0.518356         27.639  \n",
      "MLP-kappa-3     0.707956  0.386435  0.532430         27.639  \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Tuning time is 28.11\n",
      "{'units': 15, 'learning_rate': 0.01, 'dropouts': 0.4000000000000001, 'activation': 'selu', 'kernel_ini': 'he_uniform', 'tuner/epochs': 2, 'tuner/initial_epoch': 0, 'tuner/bracket': 1, 'tuner/round': 0}\n",
      "                 Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
      "MLP-loss-3      0.542035  0.391173  0.142999  0.271698  0.725664  0.504827   \n",
      "MLP-accuracy-1  0.549132  0.384679  0.150182  0.316352  0.716814  0.510749   \n",
      "MLP-accuracy-2  0.511595  0.400156  0.168085  0.316352  0.716814  0.481950   \n",
      "MLP-accuracy-3  0.510592  0.367835  0.208089  0.258491  0.755162  0.479118   \n",
      "MLP-kappa-1     0.550968  0.346206  0.204774  0.266667  0.728614  0.510338   \n",
      "MLP-kappa-2     0.533524  0.390880  0.165101  0.256604  0.758112  0.498679   \n",
      "MLP-kappa-3     0.542035  0.335612  0.225218  0.288679  0.728614  0.502900   \n",
      "MLP-f1_micro-1  0.472601  0.386876  0.213946  0.249057  0.752212  0.449666   \n",
      "\n",
      "                     AUC    G-mean   Avg_Pfm  Training Time  \n",
      "MLP-loss-3      0.696171  0.359178  0.520059         26.979  \n",
      "MLP-accuracy-1  0.715896  0.372730  0.533125         27.110  \n",
      "MLP-accuracy-2  0.710113  0.378837  0.523633         27.110  \n",
      "MLP-accuracy-3  0.700249  0.377131  0.518833         27.110  \n",
      "MLP-kappa-1     0.699859  0.376739  0.528979         27.639  \n",
      "MLP-kappa-2     0.688947  0.367442  0.518356         27.639  \n",
      "MLP-kappa-3     0.707956  0.386435  0.532430         27.639  \n",
      "MLP-f1_micro-1  0.692261  0.374112  0.505347         28.105  \n",
      "                 Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
      "MLP-loss-3      0.542035  0.391173  0.142999  0.271698  0.725664  0.504827   \n",
      "MLP-accuracy-1  0.549132  0.384679  0.150182  0.316352  0.716814  0.510749   \n",
      "MLP-accuracy-2  0.511595  0.400156  0.168085  0.316352  0.716814  0.481950   \n",
      "MLP-accuracy-3  0.510592  0.367835  0.208089  0.258491  0.755162  0.479118   \n",
      "MLP-kappa-1     0.550968  0.346206  0.204774  0.266667  0.728614  0.510338   \n",
      "MLP-kappa-2     0.533524  0.390880  0.165101  0.256604  0.758112  0.498679   \n",
      "MLP-kappa-3     0.542035  0.335612  0.225218  0.288679  0.728614  0.502900   \n",
      "MLP-f1_micro-1  0.472601  0.386876  0.213946  0.249057  0.752212  0.449666   \n",
      "MLP-f1_micro-2  0.474235  0.416219  0.184330  0.307547  0.722714  0.453219   \n",
      "\n",
      "                     AUC    G-mean   Avg_Pfm  Training Time  \n",
      "MLP-loss-3      0.696171  0.359178  0.520059         26.979  \n",
      "MLP-accuracy-1  0.715896  0.372730  0.533125         27.110  \n",
      "MLP-accuracy-2  0.710113  0.378837  0.523633         27.110  \n",
      "MLP-accuracy-3  0.700249  0.377131  0.518833         27.110  \n",
      "MLP-kappa-1     0.699859  0.376739  0.528979         27.639  \n",
      "MLP-kappa-2     0.688947  0.367442  0.518356         27.639  \n",
      "MLP-kappa-3     0.707956  0.386435  0.532430         27.639  \n",
      "MLP-f1_micro-1  0.692261  0.374112  0.505347         28.105  \n",
      "MLP-f1_micro-2  0.693550  0.381556  0.509442         28.105  \n",
      "                 Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
      "MLP-loss-3      0.542035  0.391173  0.142999  0.271698  0.725664  0.504827   \n",
      "MLP-accuracy-1  0.549132  0.384679  0.150182  0.316352  0.716814  0.510749   \n",
      "MLP-accuracy-2  0.511595  0.400156  0.168085  0.316352  0.716814  0.481950   \n",
      "MLP-accuracy-3  0.510592  0.367835  0.208089  0.258491  0.755162  0.479118   \n",
      "MLP-kappa-1     0.550968  0.346206  0.204774  0.266667  0.728614  0.510338   \n",
      "MLP-kappa-2     0.533524  0.390880  0.165101  0.256604  0.758112  0.498679   \n",
      "MLP-kappa-3     0.542035  0.335612  0.225218  0.288679  0.728614  0.502900   \n",
      "MLP-f1_micro-1  0.472601  0.386876  0.213946  0.249057  0.752212  0.449666   \n",
      "MLP-f1_micro-2  0.474235  0.416219  0.184330  0.307547  0.722714  0.453219   \n",
      "MLP-f1_micro-3  0.503053  0.414950  0.151619  0.281132  0.743363  0.475386   \n",
      "\n",
      "                     AUC    G-mean   Avg_Pfm  Training Time  \n",
      "MLP-loss-3      0.696171  0.359178  0.520059         26.979  \n",
      "MLP-accuracy-1  0.715896  0.372730  0.533125         27.110  \n",
      "MLP-accuracy-2  0.710113  0.378837  0.523633         27.110  \n",
      "MLP-accuracy-3  0.700249  0.377131  0.518833         27.110  \n",
      "MLP-kappa-1     0.699859  0.376739  0.528979         27.639  \n",
      "MLP-kappa-2     0.688947  0.367442  0.518356         27.639  \n",
      "MLP-kappa-3     0.707956  0.386435  0.532430         27.639  \n",
      "MLP-f1_micro-1  0.692261  0.374112  0.505347         28.105  \n",
      "MLP-f1_micro-2  0.693550  0.381556  0.509442         28.105  \n",
      "MLP-f1_micro-3  0.705762  0.366518  0.515888         28.105  \n",
      "                        loss                          accuracy          kappa  \\\n",
      "units                     15                                15              5   \n",
      "learning_rate           0.01                              0.01           0.01   \n",
      "dropouts                 0.4                               0.2            0.3   \n",
      "activation              selu                           sigmoid           selu   \n",
      "kernel_ini           uniform                     glorot_normal  lecun_uniform   \n",
      "tuner/epochs               5                                 5              2   \n",
      "tuner/initial_epoch        0                                 2              0   \n",
      "tuner/bracket              0                                 1              1   \n",
      "tuner/round                0                                 1              0   \n",
      "tuner/trial_id           NaN  26e69834bde1768efbb75574f11b565d            NaN   \n",
      "\n",
      "                       f1_micro  \n",
      "units                        15  \n",
      "learning_rate              0.01  \n",
      "dropouts                    0.4  \n",
      "activation                 selu  \n",
      "kernel_ini           he_uniform  \n",
      "tuner/epochs                  2  \n",
      "tuner/initial_epoch           0  \n",
      "tuner/bracket                 1  \n",
      "tuner/round                   0  \n",
      "tuner/trial_id              NaN  \n",
      "                 Class 0   Class 1   Class 2   Class 3   Class 4  Accuracy  \\\n",
      "MLP-loss-3      0.542035  0.391173  0.142999  0.271698  0.725664  0.504827   \n",
      "MLP-accuracy-1  0.549132  0.384679  0.150182  0.316352  0.716814  0.510749   \n",
      "MLP-accuracy-2  0.511595  0.400156  0.168085  0.316352  0.716814  0.481950   \n",
      "MLP-accuracy-3  0.510592  0.367835  0.208089  0.258491  0.755162  0.479118   \n",
      "MLP-kappa-1     0.550968  0.346206  0.204774  0.266667  0.728614  0.510338   \n",
      "MLP-kappa-2     0.533524  0.390880  0.165101  0.256604  0.758112  0.498679   \n",
      "MLP-kappa-3     0.542035  0.335612  0.225218  0.288679  0.728614  0.502900   \n",
      "MLP-f1_micro-1  0.472601  0.386876  0.213946  0.249057  0.752212  0.449666   \n",
      "MLP-f1_micro-2  0.474235  0.416219  0.184330  0.307547  0.722714  0.453219   \n",
      "MLP-f1_micro-3  0.503053  0.414950  0.151619  0.281132  0.743363  0.475386   \n",
      "\n",
      "                     AUC    G-mean   Avg_Pfm  Training Time  \n",
      "MLP-loss-3      0.696171  0.359178  0.520059         26.979  \n",
      "MLP-accuracy-1  0.715896  0.372730  0.533125         27.110  \n",
      "MLP-accuracy-2  0.710113  0.378837  0.523633         27.110  \n",
      "MLP-accuracy-3  0.700249  0.377131  0.518833         27.110  \n",
      "MLP-kappa-1     0.699859  0.376739  0.528979         27.639  \n",
      "MLP-kappa-2     0.688947  0.367442  0.518356         27.639  \n",
      "MLP-kappa-3     0.707956  0.386435  0.532430         27.639  \n",
      "MLP-f1_micro-1  0.692261  0.374112  0.505347         28.105  \n",
      "MLP-f1_micro-2  0.693550  0.381556  0.509442         28.105  \n",
      "MLP-f1_micro-3  0.705762  0.366518  0.515888         28.105  \n"
     ]
    }
   ],
   "source": [
    "bps = pd.DataFrame()\n",
    "for obj in metr:\n",
    "    start = time.time()\n",
    "    if obj in ['loss','accuracy']:\n",
    "        goal = obj\n",
    "    else:\n",
    "        goal = kt.Objective('val_'+obj, direction=\"max\")\n",
    "    tuner = Hyperband(build_model,\n",
    "                     objective = goal, \n",
    "                     max_epochs = MAX_EPOCHS,\n",
    "                     factor = FACTOR,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'val_'+ obj+'_'+time.ctime())\n",
    "    tuner.search(X_res, y_res,\n",
    "                 epochs=MAX_EPOCHS,batch_size=2048,\n",
    "                 verbose=0,\n",
    "                 callbacks=[early_stops(obj)],\n",
    "                 validation_data=(X_val, y_val))\n",
    "    end = time.time()\n",
    "\n",
    "    print('Tuning time is %.2f' % (end-start))\n",
    "    print(tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values)\n",
    "    bp = pd.Series(tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values,name=obj)\n",
    "    bp = bp.append(pd.Series(end-start,index=['Tuning_time']))\n",
    "    bps = pd.concat((bps,bp),axis=1)\n",
    "    models = tuner.get_best_models(num_models=FACTOR)\n",
    "    for i in range(FACTOR):\n",
    "        Y_pred = models[i].predict(X_test)\n",
    "        rsts = rsts.append(get_accs(y_test.values,Y_pred,end-start,'MLP-'+obj+'-'+str(i+1)))\n",
    "        rsts.to_csv('VCA_Tuning1.csv')\n",
    "print(bps)\n",
    "print(rsts.iloc[:,5:])\n",
    "bps.to_csv('VCA_Tuning1_bps.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "VCA_2.1_MLP_earlystopping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
