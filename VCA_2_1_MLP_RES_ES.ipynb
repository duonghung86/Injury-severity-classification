{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/duonghung86/Injury-severity-classification/blob/main/VCA_2_1_MLP_earlystopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bo-3JT-1cl14",
    "outputId": "c710009f-72c5-44ef-9e68-7b27f7c8d34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 202.3 gigabytes of available RAM\n",
      "\n",
      "Current system-wide CPU utilization %:  0.0\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory,cpu_percent\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "print('Current system-wide CPU utilization %: ',cpu_percent())\n",
    "#Remove all warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ond2r97pZvoF",
    "outputId": "090a81b4-6b1f-46d8-abb5-725257820a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler # Standardization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler,BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,NearMiss,EditedNearestNeighbours\n",
    "# Machine learning algos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Metrics\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import feature_column  # for data wrangling\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow_addons.metrics import CohenKappa,F1Score\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "#Remove all warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMFYXIMkFSak",
    "outputId": "d80430a7-b93b-421a-a2d9-3b1cbf3e5ba5"
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/duonghung86/Injury-severity-classification/blob/main/Prepared%20Texas%202019.zip?raw=true' \n",
    "data_path = tf.keras.utils.get_file(origin=url, fname=url.split('/')[-1].split('?')[0], extract=True)\n",
    "data_path = data_path.replace('%20',' ').replace('.zip','.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "UPLNCpWjZvoG",
    "outputId": "7d652183-53ce-4328-aada-ea393cc2efce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(949856, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prsn_Injry_Sev</th>\n",
       "      <th>Prsn_Age</th>\n",
       "      <th>Prsn_Gndr</th>\n",
       "      <th>Wthr_Cond</th>\n",
       "      <th>Light_Cond</th>\n",
       "      <th>Surf_Cond</th>\n",
       "      <th>Veh_Body_Styl</th>\n",
       "      <th>Prsn_Rest</th>\n",
       "      <th>Prsn_Drg_Rslt</th>\n",
       "      <th>Harm_Evnt</th>\n",
       "      <th>Rural</th>\n",
       "      <th>Crash_Speed_Limit</th>\n",
       "      <th>Road_Algn</th>\n",
       "      <th>Veh_Mod_Year</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Crash_season</th>\n",
       "      <th>Part_of_day</th>\n",
       "      <th>Collsn_type</th>\n",
       "      <th>Collsn_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>MALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PASSENGER CAR, 2-DOOR</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>STRAIGHT, LEVEL</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>ONE STRAIGHT-ONE LEFT TURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>MALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PASSENGER CAR, 2-DOOR</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>STRAIGHT, LEVEL</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>ONE STRAIGHT-ONE LEFT TURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PICKUP</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>CURVE, LEVEL</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>BOTH LEFT TURN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prsn_Injry_Sev  Prsn_Age Prsn_Gndr Wthr_Cond Light_Cond Surf_Cond  \\\n",
       "0               0        26      MALE     CLEAR   DAYLIGHT       DRY   \n",
       "1               0        52      MALE     CLEAR   DAYLIGHT       DRY   \n",
       "2               0        27    FEMALE     CLEAR   DAYLIGHT       DRY   \n",
       "\n",
       "           Veh_Body_Styl            Prsn_Rest   Prsn_Drg_Rslt  \\\n",
       "0  PASSENGER CAR, 2-DOOR  SHOULDER & LAP BELT  Not Applicable   \n",
       "1  PASSENGER CAR, 2-DOOR  SHOULDER & LAP BELT  Not Applicable   \n",
       "2                 PICKUP  SHOULDER & LAP BELT  Not Applicable   \n",
       "\n",
       "                    Harm_Evnt  Rural  Crash_Speed_Limit        Road_Algn  \\\n",
       "0  MOTOR VEHICLE IN TRANSPORT      0                 -1  STRAIGHT, LEVEL   \n",
       "1  MOTOR VEHICLE IN TRANSPORT      0                 -1  STRAIGHT, LEVEL   \n",
       "2  MOTOR VEHICLE IN TRANSPORT      1                 -1     CURVE, LEVEL   \n",
       "\n",
       "   Veh_Mod_Year  Weekend  Crash_season  Part_of_day     Collsn_type  \\\n",
       "0            33        1             3            3  SAME DIRECTION   \n",
       "1            19        1             3            3  SAME DIRECTION   \n",
       "2            16        1             3            4  SAME DIRECTION   \n",
       "\n",
       "                  Collsn_name  \n",
       "0  ONE STRAIGHT-ONE LEFT TURN  \n",
       "1  ONE STRAIGHT-ONE LEFT TURN  \n",
       "2              BOTH LEFT TURN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(data_path)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1CDPbDPYZvoH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47492, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's just use 80% of the total dataset\n",
    "df, _ = train_test_split(df, test_size=0.95,stratify = df['Prsn_Injry_Sev'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEKbv3R9ZvoH",
    "outputId": "93f16610-1110-4ffe-9c66-f4dea88ae652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All target values:\n",
      "0    39627\n",
      "1     5120\n",
      "2     2262\n",
      "3      398\n",
      "4       85\n",
      "Name: Prsn_Injry_Sev, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df['Prsn_Injry_Sev']\n",
    "print('All target values:')\n",
    "print(y.value_counts())\n",
    "X = df.drop(columns=['Prsn_Injry_Sev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUDtEBDsZvoI",
    "outputId": "b311b931-acd8-453a-95f9-b54c0b572d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical variables are  ['Prsn_Age', 'Rural', 'Crash_Speed_Limit', 'Veh_Mod_Year', 'Weekend', 'Crash_season', 'Part_of_day']\n",
      "Categorical variables that have at most 5 categories are  ['Prsn_Gndr', 'Prsn_Drg_Rslt', 'Collsn_type']\n",
      "Categorical variables that have more than 5 categories are  ['Wthr_Cond', 'Light_Cond', 'Surf_Cond', 'Veh_Body_Styl', 'Prsn_Rest', 'Harm_Evnt', 'Road_Algn', 'Collsn_name']\n",
      "WARNING:tensorflow:From /project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "New shape of the input data set: (47492, 59)\n"
     ]
    }
   ],
   "source": [
    "# %% Data wrangling -------------\n",
    "# Classify variable type\n",
    "emb_vars, ind_vars, num_vars = [], [], []\n",
    "for var in X.columns:\n",
    "    if X[var].dtypes == 'O':\n",
    "        if len(X[var].unique()) > 5:\n",
    "            emb_vars.append(var)\n",
    "        else:\n",
    "            ind_vars.append(var)\n",
    "    else:\n",
    "        num_vars.append(var)\n",
    "print('Numerical variables are ', num_vars)\n",
    "print('Categorical variables that have at most 5 categories are ', ind_vars)\n",
    "print('Categorical variables that have more than 5 categories are ', emb_vars)\n",
    "\n",
    "# Create feature columns\n",
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in num_vars:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "# bucketized cols\n",
    "# age = feature_column.numeric_column('Prsn_Age')\n",
    "# age_buckets = feature_column.bucketized_column(age, boundaries=[16, 22, 35, 55, 65])\n",
    "# feature_columns.append(age_buckets)\n",
    "# indicator_columns\n",
    "for col_name in ind_vars:\n",
    "    categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, X[col_name].unique())\n",
    "    indicator_column = feature_column.indicator_column(categorical_column)\n",
    "    feature_columns.append(indicator_column)\n",
    "# embedding columns\n",
    "for col_name in emb_vars:\n",
    "    emb_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, X[col_name].unique())\n",
    "    col_embedding = feature_column.embedding_column(emb_column, dimension=5)\n",
    "    feature_columns.append(col_embedding)\n",
    "\n",
    "# Convert all setup into new dataset\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "X = feature_layer(dict(X)).numpy()\n",
    "print('New shape of the input data set:',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EiMyeEfZvoJ",
    "outputId": "a73f13c7-932e-49e5-bb80-6c9d506ad140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (30394, 59)\n",
      "Validation features shape: (7599, 59)\n",
      "Test features shape: (9499, 59)\n"
     ]
    }
   ],
   "source": [
    "# %% Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=48)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=48)\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation features shape:', X_val.shape)\n",
    "print('Test features shape:', X_test.shape)\n",
    "\n",
    "# %% standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling #1 ...\n",
      "sampling #2 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Counter({0: 3277, 1: 3277, 2: 3277, 3: 3277, 4: 3277}), 1.6237106323242188)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dict = Counter(y_train)\n",
    "start = time.time()\n",
    "res = RandomUnderSampler(sampling_strategy={0: y_dict[1]})\n",
    "print('sampling #1 ...')\n",
    "X_train, y_train = res.fit_resample(X_train, y_train)\n",
    "res = BorderlineSMOTE(sampling_strategy='not majority')\n",
    "print('sampling #2 ...')\n",
    "X_train, y_train = res.fit_resample(X_train, y_train)\n",
    "end = time.time()\n",
    "res_time = end-start\n",
    "Counter(y_train),res_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='cohen_kappa',\n",
    "                   verbose=1, patience=10, mode='max',\n",
    "                   restore_best_weights=True)\n",
    "def create_mlp():\n",
    "    MLP = Sequential([Dense(10,activation='relu',\n",
    "                           input_dim=X_train.shape[1]),\n",
    "                      Dropout(0.5),\n",
    "                      Dense(5, activation='softmax')])\n",
    "    MLP.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[CohenKappa(num_classes=5,sparse_labels=True)])\n",
    "    return MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16385 samples, validate on 7599 samples\n",
      "Epoch 1/50\n",
      "16385/16385 [==============================] - 1s 53us/sample - loss: 1.5087 - cohen_kappa: 0.1825\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " axis = 1 not in [-1, 1)\n\t [[{{node metrics/cohen_kappa/StatefulPartitionedCall/confusion_matrix/stack_1}}]] [Op:__inference_distributed_function_461001]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3280cd86d35b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0;31m#   class_weight = cls_wgt,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     verbose=1, epochs=50)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# use the model to make predictions with the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  axis = 1 not in [-1, 1)\n\t [[{{node metrics/cohen_kappa/StatefulPartitionedCall/confusion_matrix/stack_1}}]] [Op:__inference_distributed_function_461001]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "model = create_mlp()\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train,\n",
    "                    callbacks=[es],\n",
    "                 #   class_weight = cls_wgt,\n",
    "                    validation_data=(X_val, y_val.values),\n",
    "                    verbose=1, epochs=50)\n",
    "end = time.time()\n",
    "# use the model to make predictions with the test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "# get the evaluation metrics\n",
    "get_accs(y_test.values, y_pred, end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ds5G6Pjhes9"
   },
   "source": [
    "# ALL mini functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GtuGulyVZvoL"
   },
   "outputs": [],
   "source": [
    "# %% Function to compare the prediction and true labels\n",
    "def get_accs(label, prediction, show=False):\n",
    "    cm = confusion_matrix(label, prediction)\n",
    "    length = cm.shape[0]\n",
    "    num_cases = len(label)\n",
    "    # global accuracy\n",
    "    glb_acc = np.trace(cm) / len(label)\n",
    "    ind_accs = cm / np.sum(cm, axis=1)[:, np.newaxis]\n",
    "    accs = [ind_accs[i, i] for i in range(length)]\n",
    "    index = ['Class {}'.format(i) for i in range(length)]\n",
    "    # Global accuracy\n",
    "    accs.append(glb_acc)\n",
    "    index.append('Overall Accuracy')\n",
    "    # G-mean\n",
    "    accs.append(geometric_mean_score(label, prediction, correction=0.001))\n",
    "    index.append('G-mean')\n",
    "    # Average perf\n",
    "    accs.append((glb_acc + accs[-1]) / 2)\n",
    "    index.append('Avg_Pfm')\n",
    "    if show:\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.heatmap(cm, xticklabels=np.arange(length), yticklabels=np.arange(length),\n",
    "                    annot=True, fmt='g', cmap=\"YlGnBu\")\n",
    "        plt.xlabel('Prediction')\n",
    "        plt.ylabel('Label')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(ind_accs * 100, xticklabels=np.arange(length), yticklabels=np.arange(length),\n",
    "                    annot=True, fmt='.2f', cmap=\"YlGnBu\")\n",
    "        plt.xlabel('Prediction')\n",
    "        plt.ylabel('Label')\n",
    "        plt.title('Normalized confusion matrix (%)')\n",
    "        plt.show()\n",
    "    out = np.array(accs).reshape(1, len(accs))\n",
    "    return pd.DataFrame(out, columns=index)\n",
    "\n",
    "def show_evolution(moni):\n",
    "    hist = pd.DataFrame(monitor.history)\n",
    "    no_metrics = np.int(hist.shape[1]/2)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6, 2), dpi=150)\n",
    "    for i in range(2):\n",
    "      hist.iloc[:,[i,no_metrics+i]].plot(ax=axes[i])\n",
    "    plt.show()\n",
    "# %% Produce an evaluation on the MLP model\n",
    "def evaluation(model, monitor, time, name):\n",
    "    # use the model to make predictions with the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    # Show evolution of the training process\n",
    "    # show_evolution(monitor)\n",
    "    # get the evaluation metrics\n",
    "    result = get_accs(y_test.values, y_pred)\n",
    "    result['Training Time'] = np.round(time, 3)\n",
    "    result.index = [name]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UDv2Pn6sZvoL",
    "outputId": "8a924722-bc7f-48c6-f927-72f63c69c69f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "DT\n",
      "RF\n",
      "    Overall Accuracy    G-mean   Avg_Pfm  Training Time\n",
      "LR          0.498052  0.375033  0.436543          0.722\n",
      "DT          0.422781  0.259401  0.341091          0.293\n",
      "RF          0.503737  0.331783  0.417760          0.918\n"
     ]
    }
   ],
   "source": [
    "wgt=None\n",
    "clfs = [LogisticRegression(solver = 'lbfgs',class_weight=wgt),\n",
    "        DecisionTreeClassifier(class_weight=wgt),\n",
    "        RandomForestClassifier(max_depth=4,class_weight=wgt)]\n",
    "clf_names = ['LR','DT','RF']\n",
    "rsts = pd.DataFrame()\n",
    "for model, name in zip(clfs,clf_names):\n",
    "    start = time.time()\n",
    "    print(name)\n",
    "    model.fit(X_train, y_train.values)\n",
    "    # use the model to make predictions with the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    end= time.time()\n",
    "    # get the evaluation metrics\n",
    "    result = get_accs(y_test.values,y_pred)\n",
    "    result['Training Time'] = np.round(end-start,3)\n",
    "    result.index = [name]\n",
    "    rsts = rsts.append(result)\n",
    "print(rsts.iloc[:,-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff6Y5pBDhsXm"
   },
   "source": [
    "# MLP functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "npiMGh2TZvoK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "w5IRiyFuZvoK"
   },
   "outputs": [],
   "source": [
    "def early_stops(metric_name):\n",
    "    es = EarlyStopping(monitor='val_'+ metric_name,\n",
    "                   verbose=1,\n",
    "                   patience=10,\n",
    "                   mode='max',\n",
    "                   restore_best_weights=True)\n",
    "    return es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nl6gMafpLK2P"
   },
   "source": [
    "# Ordinal multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "okwfjovXZvoK"
   },
   "outputs": [],
   "source": [
    "early_stop = {'accuracy':  tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
    "              'cohen_kappa': CohenKappa(num_classes=5,\n",
    "                                        #sparse_labels=True\n",
    "                                       ),\n",
    "              'f1_score': F1Score(num_classes=5,average=\"micro\",threshold=0.5),\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SE-hMuQELoqr"
   },
   "outputs": [],
   "source": [
    "def create_mlp(metric):\n",
    "    MLP = Sequential([Dense(10,\n",
    "                           activation='relu',\n",
    "                           input_dim=X_train.shape[1]\n",
    "                           ),\n",
    "                      Dropout(0.5),\n",
    "                      Dense(5, activation='softmax')])\n",
    "    MLP.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                #loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[metric]\n",
    "               )\n",
    "    return MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hKQLxFOhLe41",
    "outputId": "c3cbb798-7d42-4aa7-d563-79a62558a4da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "Train on 16385 samples, validate on 7599 samples\n",
      "Epoch 1/50\n",
      "16385/16385 [==============================] - 1s 76us/sample - loss: 1.5625 - accuracy: 0.3056 - val_loss: 1.4946 - val_accuracy: 0.4614\n",
      "Epoch 2/50\n",
      "16385/16385 [==============================] - 1s 43us/sample - loss: 1.4511 - accuracy: 0.4283 - val_loss: 1.4239 - val_accuracy: 0.5469\n",
      "Epoch 3/50\n",
      "16385/16385 [==============================] - 1s 43us/sample - loss: 1.4243 - accuracy: 0.4538 - val_loss: 1.3844 - val_accuracy: 0.5840\n",
      "Epoch 4/50\n",
      "16385/16385 [==============================] - 1s 43us/sample - loss: 1.4169 - accuracy: 0.4608 - val_loss: 1.4055 - val_accuracy: 0.5364\n",
      "Epoch 5/50\n",
      "16385/16385 [==============================] - 1s 44us/sample - loss: 1.4091 - accuracy: 0.4671 - val_loss: 1.4066 - val_accuracy: 0.5245\n",
      "Epoch 6/50\n",
      "16385/16385 [==============================] - 1s 43us/sample - loss: 1.4037 - accuracy: 0.4684 - val_loss: 1.4002 - val_accuracy: 0.5434\n",
      "Epoch 7/50\n",
      "16385/16385 [==============================] - 1s 46us/sample - loss: 1.4010 - accuracy: 0.4709 - val_loss: 1.3920 - val_accuracy: 0.5576\n",
      "Epoch 8/50\n",
      "16385/16385 [==============================] - 1s 43us/sample - loss: 1.3926 - accuracy: 0.4817 - val_loss: 1.4110 - val_accuracy: 0.5172\n",
      "Epoch 9/50\n",
      "16385/16385 [==============================] - 1s 46us/sample - loss: 1.3931 - accuracy: 0.4785 - val_loss: 1.4169 - val_accuracy: 0.5007\n",
      "Epoch 10/50\n",
      "16385/16385 [==============================] - 1s 47us/sample - loss: 1.3876 - accuracy: 0.4848 - val_loss: 1.4156 - val_accuracy: 0.4966\n",
      "Epoch 11/50\n",
      "16385/16385 [==============================] - 1s 43us/sample - loss: 1.3836 - accuracy: 0.4931 - val_loss: 1.4092 - val_accuracy: 0.5047\n",
      "Epoch 12/50\n",
      "16385/16385 [==============================] - 1s 44us/sample - loss: 1.3867 - accuracy: 0.4857 - val_loss: 1.4075 - val_accuracy: 0.5176\n",
      "Epoch 13/50\n",
      "16288/16385 [============================>.] - ETA: 0s - loss: 1.3804 - accuracy: 0.4982Restoring model weights from the end of the best epoch.\n",
      "16385/16385 [==============================] - 1s 47us/sample - loss: 1.3807 - accuracy: 0.4979 - val_loss: 1.4179 - val_accuracy: 0.4910\n",
      "Epoch 00013: early stopping\n",
      "cohen_kappa\n",
      "Train on 16385 samples, validate on 7599 samples\n",
      "Epoch 1/50\n",
      "16096/16385 [============================>.] - ETA: 0s - loss: 1.5149 - cohen_kappa: 0.0000e+00WARNING:tensorflow:Early stopping conditioned on metric `val_cohen_kappa` which is not available. Available metrics are: loss,cohen_kappa\n",
      "16385/16385 [==============================] - 1s 50us/sample - loss: 1.5138 - cohen_kappa: 0.0000e+00\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " axis = 1 not in [-1, 1)\n\t [[{{node metrics/cohen_kappa/StatefulPartitionedCall/confusion_matrix/stack_1}}]] [Op:__inference_distributed_function_230791]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-50ae6927093f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     verbose=1, epochs=50)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrsts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'MLP '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  axis = 1 not in [-1, 1)\n\t [[{{node metrics/cohen_kappa/StatefulPartitionedCall/confusion_matrix/stack_1}}]] [Op:__inference_distributed_function_230791]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "for name, metric in early_stop.items():\n",
    "    print(name)\n",
    "    model = create_mlp(metric)\n",
    "    start = time.time()\n",
    "    monitor = model.fit(X_train, y_train,\n",
    "                    callbacks=[early_stops(name)],\n",
    "                    validation_data=(X_val, y_val.values),\n",
    "                    verbose=1, epochs=50)\n",
    "    end = time.time()\n",
    "    rsts = rsts.append(evaluation(model, monitor, end - start,  'MLP '+ name))\n",
    "print(rsts.iloc[:,-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YC-R3A56Lxn7"
   },
   "source": [
    "# One-hot encoded multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BICiC9fdwOSw"
   },
   "outputs": [],
   "source": [
    " early_stop = {'auc':       tf.keras.metrics.AUC(name='auc'),\n",
    "     'accuracy':  tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "               'precision': tf.keras.metrics.Precision(name='precision'),\n",
    "               'recall':    tf.keras.metrics.Recall(name='recall'),\n",
    "               \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "0TY-s6q5ZvoK"
   },
   "outputs": [],
   "source": [
    "def create_mlp(metric):\n",
    "    MLP = Sequential([Dense(10,\n",
    "                           activation='relu',\n",
    "                           input_dim=X_train.shape[1]\n",
    "                           ),\n",
    "                      Dropout(0.5),\n",
    "                      Dense(5, activation='softmax')])\n",
    "    MLP.compile(optimizer='adam',\n",
    "                #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[metric]\n",
    "               )\n",
    "    return MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "UbG3CxlaUxKp"
   },
   "outputs": [],
   "source": [
    "#rsts = rsts.iloc[:6,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "78EjwO6URzui",
    "outputId": "4829623c-88b1-489f-f63e-e06883fb5780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "accuracy\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "precision\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "recall\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "                  Overall Accuracy    G-mean   Avg_Pfm  Training Time\n",
      "LR                        0.498052  0.375033  0.436543          0.722\n",
      "DT                        0.422781  0.259401  0.341091          0.293\n",
      "RF                        0.503737  0.331783  0.417760          0.918\n",
      "MLP accuracy              0.508159  0.370940  0.439550         15.952\n",
      "MLP accuracy              0.469734  0.359716  0.414725         13.669\n",
      "MLP accuracy              0.567639  0.343664  0.455651          8.656\n",
      "MLP accuracy              0.509843  0.385545  0.447694         20.709\n",
      "MLP accuracy              0.593852  0.362608  0.478230         10.016\n",
      "MLP 1H auc                0.496789  0.358532  0.427661         17.954\n",
      "MLP 1H accuracy           0.458890  0.387116  0.423003         19.406\n",
      "MLP 1H precision          0.488157  0.367163  0.427660         15.454\n",
      "MLP 1H recall             0.462364  0.360582  0.411473         17.721\n"
     ]
    }
   ],
   "source": [
    "for name, metric in early_stop.items():\n",
    "    print(name)\n",
    "    model = create_mlp(metric)\n",
    "    start = time.time()\n",
    "    monitor = model.fit(X_train, pd.get_dummies(y_train).values,\n",
    "                    callbacks=[early_stops(name)],\n",
    "                    validation_data=(X_val, pd.get_dummies(y_val).values),\n",
    "                    verbose=0, epochs=50)\n",
    "    end = time.time()\n",
    "    rsts = rsts.append(evaluation(model, monitor, end - start,  'MLP 1H '+ name))\n",
    "print(rsts.iloc[:,-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsts.to_csv('VCA_Res_Early_stopping.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "VCA_2.1_MLP_earlystopping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
