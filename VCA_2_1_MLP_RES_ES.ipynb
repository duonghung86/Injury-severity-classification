{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/duonghung86/Injury-severity-classification/blob/main/VCA_2_1_MLP_earlystopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bo-3JT-1cl14",
    "outputId": "c710009f-72c5-44ef-9e68-7b27f7c8d34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 270.0 gigabytes of available RAM\n",
      "\n",
      "Current system-wide CPU utilization %:  60.0\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory,cpu_percent\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "print('Current system-wide CPU utilization %: ',cpu_percent())\n",
    "#Remove all warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ond2r97pZvoF",
    "outputId": "090a81b4-6b1f-46d8-abb5-725257820a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler # Standardization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler,BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,NearMiss,EditedNearestNeighbours\n",
    "# Machine learning algos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Metrics\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import feature_column  # for data wrangling\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow_addons.metrics import CohenKappa,F1Score\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "#Remove all warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMFYXIMkFSak",
    "outputId": "d80430a7-b93b-421a-a2d9-3b1cbf3e5ba5"
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/duonghung86/Injury-severity-classification/blob/main/Prepared%20Texas%202019.zip?raw=true' \n",
    "data_path = tf.keras.utils.get_file(origin=url, fname=url.split('/')[-1].split('?')[0], extract=True)\n",
    "data_path = data_path.replace('%20',' ').replace('.zip','.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "UPLNCpWjZvoG",
    "outputId": "7d652183-53ce-4328-aada-ea393cc2efce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(949856, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prsn_Injry_Sev</th>\n",
       "      <th>Prsn_Age</th>\n",
       "      <th>Prsn_Gndr</th>\n",
       "      <th>Wthr_Cond</th>\n",
       "      <th>Light_Cond</th>\n",
       "      <th>Surf_Cond</th>\n",
       "      <th>Veh_Body_Styl</th>\n",
       "      <th>Prsn_Rest</th>\n",
       "      <th>Prsn_Drg_Rslt</th>\n",
       "      <th>Harm_Evnt</th>\n",
       "      <th>Rural</th>\n",
       "      <th>Crash_Speed_Limit</th>\n",
       "      <th>Road_Algn</th>\n",
       "      <th>Veh_Mod_Year</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Crash_season</th>\n",
       "      <th>Part_of_day</th>\n",
       "      <th>Collsn_type</th>\n",
       "      <th>Collsn_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>MALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PASSENGER CAR, 2-DOOR</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>STRAIGHT, LEVEL</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>ONE STRAIGHT-ONE LEFT TURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>MALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PASSENGER CAR, 2-DOOR</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>STRAIGHT, LEVEL</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>ONE STRAIGHT-ONE LEFT TURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PICKUP</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>CURVE, LEVEL</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>BOTH LEFT TURN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prsn_Injry_Sev  Prsn_Age Prsn_Gndr Wthr_Cond Light_Cond Surf_Cond  \\\n",
       "0               0        26      MALE     CLEAR   DAYLIGHT       DRY   \n",
       "1               0        52      MALE     CLEAR   DAYLIGHT       DRY   \n",
       "2               0        27    FEMALE     CLEAR   DAYLIGHT       DRY   \n",
       "\n",
       "           Veh_Body_Styl            Prsn_Rest   Prsn_Drg_Rslt  \\\n",
       "0  PASSENGER CAR, 2-DOOR  SHOULDER & LAP BELT  Not Applicable   \n",
       "1  PASSENGER CAR, 2-DOOR  SHOULDER & LAP BELT  Not Applicable   \n",
       "2                 PICKUP  SHOULDER & LAP BELT  Not Applicable   \n",
       "\n",
       "                    Harm_Evnt  Rural  Crash_Speed_Limit        Road_Algn  \\\n",
       "0  MOTOR VEHICLE IN TRANSPORT      0                 -1  STRAIGHT, LEVEL   \n",
       "1  MOTOR VEHICLE IN TRANSPORT      0                 -1  STRAIGHT, LEVEL   \n",
       "2  MOTOR VEHICLE IN TRANSPORT      1                 -1     CURVE, LEVEL   \n",
       "\n",
       "   Veh_Mod_Year  Weekend  Crash_season  Part_of_day     Collsn_type  \\\n",
       "0            33        1             3            3  SAME DIRECTION   \n",
       "1            19        1             3            3  SAME DIRECTION   \n",
       "2            16        1             3            4  SAME DIRECTION   \n",
       "\n",
       "                  Collsn_name  \n",
       "0  ONE STRAIGHT-ONE LEFT TURN  \n",
       "1  ONE STRAIGHT-ONE LEFT TURN  \n",
       "2              BOTH LEFT TURN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(data_path)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1CDPbDPYZvoH"
   },
   "outputs": [],
   "source": [
    "# Let's just use 80% of the total dataset\n",
    "df, _ = train_test_split(df, test_size=0.6,stratify = df['Prsn_Injry_Sev'])\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEKbv3R9ZvoH",
    "outputId": "93f16610-1110-4ffe-9c66-f4dea88ae652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All target values:\n",
      "0    317023\n",
      "1     40964\n",
      "2     18097\n",
      "3      3180\n",
      "4       678\n",
      "Name: Prsn_Injry_Sev, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df['Prsn_Injry_Sev']\n",
    "print('All target values:')\n",
    "print(y.value_counts())\n",
    "X = df.drop(columns=['Prsn_Injry_Sev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUDtEBDsZvoI",
    "outputId": "b311b931-acd8-453a-95f9-b54c0b572d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical variables are  ['Prsn_Age', 'Rural', 'Crash_Speed_Limit', 'Veh_Mod_Year', 'Weekend', 'Crash_season', 'Part_of_day']\n",
      "Categorical variables that have at most 5 categories are  ['Prsn_Gndr', 'Prsn_Drg_Rslt', 'Collsn_type']\n",
      "Categorical variables that have more than 5 categories are  ['Wthr_Cond', 'Light_Cond', 'Surf_Cond', 'Veh_Body_Styl', 'Prsn_Rest', 'Harm_Evnt', 'Road_Algn', 'Collsn_name']\n",
      "WARNING:tensorflow:From /project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "New shape of the input data set: (379942, 59)\n"
     ]
    }
   ],
   "source": [
    "# %% Data wrangling -------------\n",
    "# Classify variable type\n",
    "emb_vars, ind_vars, num_vars = [], [], []\n",
    "for var in X.columns:\n",
    "    if X[var].dtypes == 'O':\n",
    "        if len(X[var].unique()) > 5:\n",
    "            emb_vars.append(var)\n",
    "        else:\n",
    "            ind_vars.append(var)\n",
    "    else:\n",
    "        num_vars.append(var)\n",
    "print('Numerical variables are ', num_vars)\n",
    "print('Categorical variables that have at most 5 categories are ', ind_vars)\n",
    "print('Categorical variables that have more than 5 categories are ', emb_vars)\n",
    "\n",
    "# Create feature columns\n",
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in num_vars:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "# bucketized cols\n",
    "# age = feature_column.numeric_column('Prsn_Age')\n",
    "# age_buckets = feature_column.bucketized_column(age, boundaries=[16, 22, 35, 55, 65])\n",
    "# feature_columns.append(age_buckets)\n",
    "# indicator_columns\n",
    "for col_name in ind_vars:\n",
    "    categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, X[col_name].unique())\n",
    "    indicator_column = feature_column.indicator_column(categorical_column)\n",
    "    feature_columns.append(indicator_column)\n",
    "# embedding columns\n",
    "for col_name in emb_vars:\n",
    "    emb_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, X[col_name].unique())\n",
    "    col_embedding = feature_column.embedding_column(emb_column, dimension=5)\n",
    "    feature_columns.append(col_embedding)\n",
    "\n",
    "# Convert all setup into new dataset\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "X = feature_layer(dict(X)).numpy()\n",
    "print('New shape of the input data set:',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EiMyeEfZvoJ",
    "outputId": "a73f13c7-932e-49e5-bb80-6c9d506ad140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (243162, 59)\n",
      "Validation features shape: (60791, 59)\n",
      "Test features shape: (75989, 59)\n"
     ]
    }
   ],
   "source": [
    "# %% Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=48)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=48)\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation features shape:', X_val.shape)\n",
    "print('Test features shape:', X_test.shape)\n",
    "\n",
    "# %% standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling #1 ...\n",
      "sampling #2 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Counter({0: 26217, 1: 26217, 2: 26217, 3: 26217, 4: 26217}),\n",
       " 11.922038555145264)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dict = Counter(y_train)\n",
    "start = time.time()\n",
    "res = RandomUnderSampler(sampling_strategy={0: y_dict[1]})\n",
    "print('sampling #1 ...')\n",
    "X_train, y_train = res.fit_resample(X_train, y_train)\n",
    "res = SMOTE(sampling_strategy='not majority')\n",
    "print('sampling #2 ...')\n",
    "X_train, y_train = res.fit_resample(X_train, y_train)\n",
    "end = time.time()\n",
    "res_time = end-start\n",
    "Counter(y_train),res_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ds5G6Pjhes9"
   },
   "source": [
    "# ALL mini functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GtuGulyVZvoL"
   },
   "outputs": [],
   "source": [
    "# %% Function to compare the prediction and true labels\n",
    "def get_accs(label, prediction, show=False):\n",
    "    cm = confusion_matrix(label, prediction)\n",
    "    length = cm.shape[0]\n",
    "    num_cases = len(label)\n",
    "    # global accuracy\n",
    "    glb_acc = np.trace(cm) / len(label)\n",
    "    ind_accs = cm / np.sum(cm, axis=1)[:, np.newaxis]\n",
    "    accs = [ind_accs[i, i] for i in range(length)]\n",
    "    index = ['Class {}'.format(i) for i in range(length)]\n",
    "    # Global accuracy\n",
    "    accs.append(glb_acc)\n",
    "    index.append('Overall Accuracy')\n",
    "    # G-mean\n",
    "    accs.append(geometric_mean_score(label, prediction, correction=0.001))\n",
    "    index.append('G-mean')\n",
    "    # Average perf\n",
    "    accs.append((glb_acc + accs[-1]) / 2)\n",
    "    index.append('Avg_Pfm')\n",
    "    if show:\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.heatmap(cm, xticklabels=np.arange(length), yticklabels=np.arange(length),\n",
    "                    annot=True, fmt='g', cmap=\"YlGnBu\")\n",
    "        plt.xlabel('Prediction')\n",
    "        plt.ylabel('Label')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(ind_accs * 100, xticklabels=np.arange(length), yticklabels=np.arange(length),\n",
    "                    annot=True, fmt='.2f', cmap=\"YlGnBu\")\n",
    "        plt.xlabel('Prediction')\n",
    "        plt.ylabel('Label')\n",
    "        plt.title('Normalized confusion matrix (%)')\n",
    "        plt.show()\n",
    "    out = np.array(accs).reshape(1, len(accs))\n",
    "    return pd.DataFrame(out, columns=index)\n",
    "\n",
    "def show_evolution(moni):\n",
    "    hist = pd.DataFrame(monitor.history)\n",
    "    no_metrics = np.int(hist.shape[1]/2)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6, 2), dpi=150)\n",
    "    for i in range(2):\n",
    "      hist.iloc[:,[i,no_metrics+i]].plot(ax=axes[i])\n",
    "    plt.show()\n",
    "# %% Produce an evaluation on the MLP model\n",
    "def evaluation(model, monitor, time, name):\n",
    "    # use the model to make predictions with the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    # Show evolution of the training process\n",
    "    # show_evolution(monitor)\n",
    "    # get the evaluation metrics\n",
    "    result = get_accs(y_test.values, y_pred)\n",
    "    result['Training Time'] = np.round(time, 3)\n",
    "    result.index = [name]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UDv2Pn6sZvoL",
    "outputId": "8a924722-bc7f-48c6-f927-72f63c69c69f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "DT\n",
      "RF\n",
      "    Overall Accuracy    G-mean   Avg_Pfm  Training Time\n",
      "LR          0.485426  0.373352  0.429389          7.376\n",
      "DT          0.426206  0.254368  0.340287          3.510\n",
      "RF          0.504586  0.323509  0.414048         10.585\n"
     ]
    }
   ],
   "source": [
    "wgt=None\n",
    "clfs = [LogisticRegression(solver = 'lbfgs',class_weight=wgt),\n",
    "        DecisionTreeClassifier(class_weight=wgt),\n",
    "        RandomForestClassifier(max_depth=4,class_weight=wgt)]\n",
    "clf_names = ['LR','DT','RF']\n",
    "rsts = pd.DataFrame()\n",
    "for model, name in zip(clfs,clf_names):\n",
    "    start = time.time()\n",
    "    print(name)\n",
    "    model.fit(X_train, y_train.values)\n",
    "    # use the model to make predictions with the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    end= time.time()\n",
    "    # get the evaluation metrics\n",
    "    result = get_accs(y_test.values,y_pred)\n",
    "    result['Training Time'] = np.round(end-start,3)\n",
    "    result.index = [name]\n",
    "    rsts = rsts.append(result)\n",
    "print(rsts.iloc[:,-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff6Y5pBDhsXm"
   },
   "source": [
    "# MLP functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "w5IRiyFuZvoK"
   },
   "outputs": [],
   "source": [
    "def early_stops(metric_name):\n",
    "    es = EarlyStopping(monitor='val_'+ metric_name,\n",
    "                   verbose=1,\n",
    "                   patience=10,\n",
    "                   mode='max',\n",
    "                   restore_best_weights=True)\n",
    "    return es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nl6gMafpLK2P"
   },
   "source": [
    "# Ordinal multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "okwfjovXZvoK"
   },
   "outputs": [],
   "source": [
    "early_stop = {'accuracy':  tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
    "              'cohen_kappa': CohenKappa(num_classes=5,\n",
    "                                        #sparse_labels=True\n",
    "                                       ),\n",
    "              'f1_micro': F1Score(num_classes=5,average=\"micro\",threshold=0.5, name='f1_micro'),\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SE-hMuQELoqr"
   },
   "outputs": [],
   "source": [
    "def create_mlp(metric):\n",
    "    MLP = Sequential([Dense(10,\n",
    "                           activation='relu',\n",
    "                           input_dim=X_train.shape[1]\n",
    "                           ),\n",
    "                      Dropout(0.5),\n",
    "                      Dense(5, activation='softmax')])\n",
    "    MLP.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                #loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[metric]\n",
    "               )\n",
    "    return MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hKQLxFOhLe41",
    "outputId": "c3cbb798-7d42-4aa7-d563-79a62558a4da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "Train on 131085 samples, validate on 60791 samples\n",
      "Epoch 1/50\n",
      "131085/131085 [==============================] - 7s 53us/sample - loss: 1.5000 - accuracy: 0.3674 - val_loss: 1.4289 - val_accuracy: 0.4877\n",
      "Epoch 2/50\n",
      "131085/131085 [==============================] - 7s 50us/sample - loss: 1.4683 - accuracy: 0.4032 - val_loss: 1.3861 - val_accuracy: 0.5368\n",
      "Epoch 3/50\n",
      "131085/131085 [==============================] - 7s 50us/sample - loss: 1.4629 - accuracy: 0.4094 - val_loss: 1.4006 - val_accuracy: 0.4984\n",
      "Epoch 4/50\n",
      "131085/131085 [==============================] - 7s 50us/sample - loss: 1.4604 - accuracy: 0.4109 - val_loss: 1.4151 - val_accuracy: 0.4624\n",
      "Epoch 5/50\n",
      "131085/131085 [==============================] - 7s 50us/sample - loss: 1.4589 - accuracy: 0.4150 - val_loss: 1.4193 - val_accuracy: 0.4497\n",
      "Epoch 6/50\n",
      "131085/131085 [==============================] - 7s 50us/sample - loss: 1.4577 - accuracy: 0.4171 - val_loss: 1.3845 - val_accuracy: 0.5027\n",
      "Epoch 7/50\n",
      "131085/131085 [==============================] - 7s 50us/sample - loss: 1.4568 - accuracy: 0.4163 - val_loss: 1.4240 - val_accuracy: 0.4347\n",
      "Epoch 8/50\n",
      "131085/131085 [==============================] - 7s 50us/sample - loss: 1.4558 - accuracy: 0.4171 - val_loss: 1.4010 - val_accuracy: 0.4670\n",
      "Epoch 9/50\n",
      "131085/131085 [==============================] - 6s 49us/sample - loss: 1.4548 - accuracy: 0.4185 - val_loss: 1.4114 - val_accuracy: 0.4471\n",
      "Epoch 10/50\n",
      "131085/131085 [==============================] - 6s 49us/sample - loss: 1.4541 - accuracy: 0.4200 - val_loss: 1.4181 - val_accuracy: 0.4380\n",
      "Epoch 11/50\n",
      "131085/131085 [==============================] - 7s 50us/sample - loss: 1.4531 - accuracy: 0.4224 - val_loss: 1.4067 - val_accuracy: 0.4546\n",
      "Epoch 12/50\n",
      "130176/131085 [============================>.] - ETA: 0s - loss: 1.4537 - accuracy: 0.4204Restoring model weights from the end of the best epoch.\n",
      "131085/131085 [==============================] - 7s 50us/sample - loss: 1.4536 - accuracy: 0.4205 - val_loss: 1.4166 - val_accuracy: 0.4409\n",
      "Epoch 00012: early stopping\n",
      "cohen_kappa\n",
      "Train on 131085 samples, validate on 60791 samples\n",
      "Epoch 1/50\n",
      "131085/131085 [==============================] - 8s 58us/sample - loss: 1.4915 - cohen_kappa: 0.0000e+00 - val_loss: 1.4448 - val_cohen_kappa: -1.1921e-07\n",
      "Epoch 2/50\n",
      "131085/131085 [==============================] - 7s 54us/sample - loss: 1.4663 - cohen_kappa: 0.0000e+00 - val_loss: 1.4604 - val_cohen_kappa: -1.1921e-07\n",
      "Epoch 3/50\n",
      "131085/131085 [==============================] - 7s 53us/sample - loss: 1.4600 - cohen_kappa: 0.0000e+00 - val_loss: 1.4369 - val_cohen_kappa: 1.1921e-07\n",
      "Epoch 4/50\n",
      "131085/131085 [==============================] - 7s 54us/sample - loss: 1.4570 - cohen_kappa: -1.1921e-07 - val_loss: 1.4368 - val_cohen_kappa: 0.0000e+00\n",
      "Epoch 5/50\n",
      "131085/131085 [==============================] - 7s 53us/sample - loss: 1.4554 - cohen_kappa: 0.0000e+00 - val_loss: 1.4479 - val_cohen_kappa: 0.0000e+00\n",
      "Epoch 6/50\n",
      "131085/131085 [==============================] - 7s 54us/sample - loss: 1.4536 - cohen_kappa: 0.0000e+00 - val_loss: 1.4261 - val_cohen_kappa: 0.0000e+00\n",
      "Epoch 7/50\n",
      "131085/131085 [==============================] - 7s 53us/sample - loss: 1.4521 - cohen_kappa: -1.1921e-07 - val_loss: 1.4411 - val_cohen_kappa: -1.1921e-07\n",
      "Epoch 8/50\n",
      "131085/131085 [==============================] - 7s 54us/sample - loss: 1.4506 - cohen_kappa: 0.0000e+00 - val_loss: 1.4405 - val_cohen_kappa: 1.1921e-07\n",
      "Epoch 9/50\n",
      "131085/131085 [==============================] - 7s 54us/sample - loss: 1.4513 - cohen_kappa: 5.9605e-08 - val_loss: 1.4304 - val_cohen_kappa: -1.1921e-07\n",
      "Epoch 10/50\n",
      "131085/131085 [==============================] - 7s 54us/sample - loss: 1.4501 - cohen_kappa: 0.0000e+00 - val_loss: 1.4128 - val_cohen_kappa: 0.0000e+00\n",
      "Epoch 11/50\n",
      "131085/131085 [==============================] - 7s 54us/sample - loss: 1.4491 - cohen_kappa: 5.9605e-08 - val_loss: 1.4277 - val_cohen_kappa: 0.0000e+00\n",
      "Epoch 12/50\n",
      "131085/131085 [==============================] - 7s 54us/sample - loss: 1.4484 - cohen_kappa: 0.0000e+00 - val_loss: 1.4138 - val_cohen_kappa: 0.0000e+00\n",
      "Epoch 13/50\n",
      "130304/131085 [============================>.] - ETA: 0s - loss: 1.4489 - cohen_kappa: -1.1921e-07Restoring model weights from the end of the best epoch.\n",
      "131085/131085 [==============================] - 7s 54us/sample - loss: 1.4489 - cohen_kappa: 0.0000e+00 - val_loss: 1.4209 - val_cohen_kappa: 0.0000e+00\n",
      "Epoch 00013: early stopping\n",
      "f1_micro\n",
      "Train on 131085 samples, validate on 60791 samples\n",
      "Epoch 1/50\n",
      "131085/131085 [==============================] - 7s 55us/sample - loss: 1.4926 - f1_micro: 0.1810 - val_loss: 1.4395 - val_f1_micro: 0.1142\n",
      "Epoch 2/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4683 - f1_micro: 0.2048 - val_loss: 1.4392 - val_f1_micro: 0.1340\n",
      "Epoch 3/50\n",
      "131085/131085 [==============================] - 7s 53us/sample - loss: 1.4642 - f1_micro: 0.2116 - val_loss: 1.4420 - val_f1_micro: 0.1368\n",
      "Epoch 4/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4612 - f1_micro: 0.2159 - val_loss: 1.4279 - val_f1_micro: 0.1413\n",
      "Epoch 5/50\n",
      "131085/131085 [==============================] - 7s 53us/sample - loss: 1.4599 - f1_micro: 0.2143 - val_loss: 1.4431 - val_f1_micro: 0.1333\n",
      "Epoch 6/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4593 - f1_micro: 0.2123 - val_loss: 1.4263 - val_f1_micro: 0.1309\n",
      "Epoch 7/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4572 - f1_micro: 0.2145 - val_loss: 1.4159 - val_f1_micro: 0.1435\n",
      "Epoch 8/50\n",
      "131085/131085 [==============================] - 7s 53us/sample - loss: 1.4556 - f1_micro: 0.2137 - val_loss: 1.4346 - val_f1_micro: 0.1278\n",
      "Epoch 9/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4543 - f1_micro: 0.2124 - val_loss: 1.4289 - val_f1_micro: 0.1329\n",
      "Epoch 10/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4550 - f1_micro: 0.2082 - val_loss: 1.4271 - val_f1_micro: 0.1367\n",
      "Epoch 11/50\n",
      "131085/131085 [==============================] - 7s 53us/sample - loss: 1.4525 - f1_micro: 0.2082 - val_loss: 1.4339 - val_f1_micro: 0.1387\n",
      "Epoch 12/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4525 - f1_micro: 0.2080 - val_loss: 1.4253 - val_f1_micro: 0.1458\n",
      "Epoch 13/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4532 - f1_micro: 0.2069 - val_loss: 1.4149 - val_f1_micro: 0.1310\n",
      "Epoch 14/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4520 - f1_micro: 0.2092 - val_loss: 1.4311 - val_f1_micro: 0.1342\n",
      "Epoch 15/50\n",
      "131085/131085 [==============================] - 7s 53us/sample - loss: 1.4522 - f1_micro: 0.2055 - val_loss: 1.4234 - val_f1_micro: 0.1340\n",
      "Epoch 16/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4524 - f1_micro: 0.2073 - val_loss: 1.4309 - val_f1_micro: 0.1323\n",
      "Epoch 17/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4509 - f1_micro: 0.2085 - val_loss: 1.4069 - val_f1_micro: 0.1348\n",
      "Epoch 18/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4516 - f1_micro: 0.2067 - val_loss: 1.4282 - val_f1_micro: 0.1366\n",
      "Epoch 19/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4507 - f1_micro: 0.2097 - val_loss: 1.4189 - val_f1_micro: 0.1191\n",
      "Epoch 20/50\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4509 - f1_micro: 0.2068 - val_loss: 1.4264 - val_f1_micro: 0.1265\n",
      "Epoch 21/50\n",
      "131085/131085 [==============================] - 7s 53us/sample - loss: 1.4507 - f1_micro: 0.2084 - val_loss: 1.4168 - val_f1_micro: 0.1309\n",
      "Epoch 22/50\n",
      "130528/131085 [============================>.] - ETA: 0s - loss: 1.4505 - f1_micro: 0.2072Restoring model weights from the end of the best epoch.\n",
      "131085/131085 [==============================] - 7s 52us/sample - loss: 1.4506 - f1_micro: 0.2072 - val_loss: 1.4202 - val_f1_micro: 0.1423\n",
      "Epoch 00022: early stopping\n",
      "                 Overall Accuracy    G-mean   Avg_Pfm  Training Time\n",
      "LR                       0.485426  0.373352  0.429389          7.376\n",
      "DT                       0.426206  0.254368  0.340287          3.510\n",
      "RF                       0.504586  0.323509  0.414048         10.585\n",
      "MLP accuracy             0.536801  0.343239  0.440020         78.825\n",
      "MLP cohen_kappa          0.473371  0.371792  0.422581         92.245\n",
      "MLP f1_micro             0.448881  0.363000  0.405941        151.464\n"
     ]
    }
   ],
   "source": [
    "for name, metric in early_stop.items():\n",
    "    print(name)\n",
    "    model = create_mlp(metric)\n",
    "    start = time.time()\n",
    "    monitor = model.fit(X_train, y_train,\n",
    "                    callbacks=[early_stops(name)],\n",
    "                    validation_data=(X_val, y_val.values),\n",
    "                    verbose=1, epochs=50)\n",
    "    end = time.time()\n",
    "    rsts = rsts.append(evaluation(model, monitor, end - start,  'MLP '+ name))\n",
    "print(rsts.iloc[:,-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YC-R3A56Lxn7"
   },
   "source": [
    "# One-hot encoded multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BICiC9fdwOSw"
   },
   "outputs": [],
   "source": [
    " early_stop = {'auc':       tf.keras.metrics.AUC(name='auc'),\n",
    "     'accuracy':  tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "               'precision': tf.keras.metrics.Precision(name='precision'),\n",
    "               'recall':    tf.keras.metrics.Recall(name='recall'),\n",
    "               \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0TY-s6q5ZvoK"
   },
   "outputs": [],
   "source": [
    "def create_mlp(metric):\n",
    "    MLP = Sequential([Dense(10,\n",
    "                           activation='relu',\n",
    "                           input_dim=X_train.shape[1]\n",
    "                           ),\n",
    "                      Dropout(0.5),\n",
    "                      Dense(5, activation='softmax')])\n",
    "    MLP.compile(optimizer='adam',\n",
    "                #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[metric]\n",
    "               )\n",
    "    return MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UbG3CxlaUxKp"
   },
   "outputs": [],
   "source": [
    "#rsts = rsts.iloc[:6,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "78EjwO6URzui",
    "outputId": "4829623c-88b1-489f-f63e-e06883fb5780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "accuracy\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "precision\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "recall\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "                  Overall Accuracy    G-mean   Avg_Pfm  Training Time\n",
      "LR                        0.485426  0.373352  0.429389          7.376\n",
      "DT                        0.426206  0.254368  0.340287          3.510\n",
      "RF                        0.504586  0.323509  0.414048         10.585\n",
      "MLP accuracy              0.536801  0.343239  0.440020         78.825\n",
      "MLP cohen_kappa           0.473371  0.371792  0.422581         92.245\n",
      "MLP f1_micro              0.448881  0.363000  0.405941        151.464\n",
      "MLP 1H auc                0.479214  0.386062  0.432638        131.711\n",
      "MLP 1H accuracy           0.507152  0.369005  0.438079         76.263\n",
      "MLP 1H precision          0.499651  0.377598  0.438625         79.733\n",
      "MLP 1H recall             0.483267  0.362186  0.422727        262.674\n"
     ]
    }
   ],
   "source": [
    "for name, metric in early_stop.items():\n",
    "    print(name)\n",
    "    model = create_mlp(metric)\n",
    "    start = time.time()\n",
    "    monitor = model.fit(X_train, pd.get_dummies(y_train).values,\n",
    "                    callbacks=[early_stops(name)],\n",
    "                    validation_data=(X_val, pd.get_dummies(y_val).values),\n",
    "                    verbose=0, epochs=50)\n",
    "    end = time.time()\n",
    "    rsts = rsts.append(evaluation(model, monitor, end - start,  'MLP 1H '+ name))\n",
    "    print(rsts.iloc[:,-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsts.to_csv('VCA_Res_Early_stopping.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "VCA_2.1_MLP_earlystopping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
