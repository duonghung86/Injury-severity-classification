{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/duonghung86/Injury-severity-classification/blob/main/VCA_2_1_MLP_resampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bo-3JT-1cl14",
    "outputId": "b0ddb98f-231d-4440-906a-56f85c191ed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 270.0 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "  print('re-execute this cell.')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uU9MzQe41HSp"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YKl2NA0NrGqs",
    "outputId": "aaf18b61-6e8d-4832-ab04-c7ae21772417"
   },
   "outputs": [],
   "source": [
    "#!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GvRpx7tyrS85",
    "outputId": "4e976b5d-bcff-4c1b-aa99-5e0a1b2f88a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "svmem(total=270038007808, available=219160035328, percent=18.8, used=49769508864, free=213269123072, active=43841691648, inactive=4530921472, buffers=355999744, cached=6643376128, shared=194473984, slab=552603648)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "# gives a single float value\n",
    "print(psutil.cpu_percent())\n",
    "# gives an object with many fields\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ond2r97pZvoF",
    "outputId": "34b10d94-ca9a-4ad7-b156-c2c3613059d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler # Standardization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Machine learning algos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler,BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,NearMiss,EditedNearestNeighbours\n",
    "# Metrics\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import feature_column  # for data wrangling\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMFYXIMkFSak",
    "outputId": "da5f08e2-a9f0-4ecf-91eb-4a8db2a0f631"
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "url = 'https://github.com/duonghung86/Injury-severity-classification/blob/main/Prepared%20Texas%202019.zip?raw=true' \n",
    "data_path = tf.keras.utils.get_file(origin=url, fname=url.split('/')[-1].split('?')[0], extract=True)\n",
    "data_path = data_path.replace('%20',' ').replace('.zip','.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "UPLNCpWjZvoG",
    "outputId": "8ffdd693-0603-4f0e-8029-4617a22ad00b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(949856, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prsn_Injry_Sev</th>\n",
       "      <th>Prsn_Age</th>\n",
       "      <th>Prsn_Gndr</th>\n",
       "      <th>Wthr_Cond</th>\n",
       "      <th>Light_Cond</th>\n",
       "      <th>Surf_Cond</th>\n",
       "      <th>Veh_Body_Styl</th>\n",
       "      <th>Prsn_Rest</th>\n",
       "      <th>Prsn_Drg_Rslt</th>\n",
       "      <th>Harm_Evnt</th>\n",
       "      <th>Rural</th>\n",
       "      <th>Crash_Speed_Limit</th>\n",
       "      <th>Road_Algn</th>\n",
       "      <th>Veh_Mod_Year</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Crash_season</th>\n",
       "      <th>Part_of_day</th>\n",
       "      <th>Collsn_type</th>\n",
       "      <th>Collsn_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>MALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PASSENGER CAR, 2-DOOR</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>STRAIGHT, LEVEL</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>ONE STRAIGHT-ONE LEFT TURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>MALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PASSENGER CAR, 2-DOOR</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>STRAIGHT, LEVEL</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>ONE STRAIGHT-ONE LEFT TURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PICKUP</td>\n",
       "      <td>SHOULDER &amp; LAP BELT</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>MOTOR VEHICLE IN TRANSPORT</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>CURVE, LEVEL</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>SAME DIRECTION</td>\n",
       "      <td>BOTH LEFT TURN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prsn_Injry_Sev  Prsn_Age Prsn_Gndr Wthr_Cond Light_Cond Surf_Cond  \\\n",
       "0               0        26      MALE     CLEAR   DAYLIGHT       DRY   \n",
       "1               0        52      MALE     CLEAR   DAYLIGHT       DRY   \n",
       "2               0        27    FEMALE     CLEAR   DAYLIGHT       DRY   \n",
       "\n",
       "           Veh_Body_Styl            Prsn_Rest   Prsn_Drg_Rslt  \\\n",
       "0  PASSENGER CAR, 2-DOOR  SHOULDER & LAP BELT  Not Applicable   \n",
       "1  PASSENGER CAR, 2-DOOR  SHOULDER & LAP BELT  Not Applicable   \n",
       "2                 PICKUP  SHOULDER & LAP BELT  Not Applicable   \n",
       "\n",
       "                    Harm_Evnt  Rural  Crash_Speed_Limit        Road_Algn  \\\n",
       "0  MOTOR VEHICLE IN TRANSPORT      0                 -1  STRAIGHT, LEVEL   \n",
       "1  MOTOR VEHICLE IN TRANSPORT      0                 -1  STRAIGHT, LEVEL   \n",
       "2  MOTOR VEHICLE IN TRANSPORT      1                 -1     CURVE, LEVEL   \n",
       "\n",
       "   Veh_Mod_Year  Weekend  Crash_season  Part_of_day     Collsn_type  \\\n",
       "0            33        1             3            3  SAME DIRECTION   \n",
       "1            19        1             3            3  SAME DIRECTION   \n",
       "2            16        1             3            4  SAME DIRECTION   \n",
       "\n",
       "                  Collsn_name  \n",
       "0  ONE STRAIGHT-ONE LEFT TURN  \n",
       "1  ONE STRAIGHT-ONE LEFT TURN  \n",
       "2              BOTH LEFT TURN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(data_path)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CDPbDPYZvoH",
    "outputId": "4cbbde59-32aa-4400-df32-70f782f350ac"
   },
   "outputs": [],
   "source": [
    "# Let's just use 80% of the total dataset\n",
    "#df, _ = train_test_split(df, test_size=0.9,stratify = df['Prsn_Injry_Sev'])\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEKbv3R9ZvoH",
    "outputId": "1d5b3fe7-2f99-44a3-ee6e-5e22105cd80b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All target values:\n",
      "0    792558\n",
      "1    102409\n",
      "2     45242\n",
      "3      7951\n",
      "4      1696\n",
      "Name: Prsn_Injry_Sev, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df['Prsn_Injry_Sev']\n",
    "print('All target values:')\n",
    "print(y.value_counts())\n",
    "X = df.drop(columns=['Prsn_Injry_Sev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUDtEBDsZvoI",
    "outputId": "1b8af306-10c7-4848-e640-a65fbc9b16f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical variables are  ['Prsn_Age', 'Rural', 'Crash_Speed_Limit', 'Veh_Mod_Year', 'Weekend', 'Crash_season', 'Part_of_day']\n",
      "Categorical variables that have at most 5 categories are  ['Prsn_Gndr', 'Prsn_Drg_Rslt', 'Collsn_type']\n",
      "Categorical variables that have more than 5 categories are  ['Wthr_Cond', 'Light_Cond', 'Surf_Cond', 'Veh_Body_Styl', 'Prsn_Rest', 'Harm_Evnt', 'Road_Algn', 'Collsn_name']\n",
      "WARNING:tensorflow:From /project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "New shape of the input data set: (949856, 59)\n"
     ]
    }
   ],
   "source": [
    "# %% Data wrangling -------------\n",
    "# Classify variable type\n",
    "emb_vars, ind_vars, num_vars = [], [], []\n",
    "for var in X.columns:\n",
    "    if X[var].dtypes == 'O':\n",
    "        if len(X[var].unique()) > 5:\n",
    "            emb_vars.append(var)\n",
    "        else:\n",
    "            ind_vars.append(var)\n",
    "    else:\n",
    "        num_vars.append(var)\n",
    "print('Numerical variables are ', num_vars)\n",
    "print('Categorical variables that have at most 5 categories are ', ind_vars)\n",
    "print('Categorical variables that have more than 5 categories are ', emb_vars)\n",
    "\n",
    "# Create feature columns\n",
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in num_vars:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "# bucketized cols\n",
    "# age = feature_column.numeric_column('Prsn_Age')\n",
    "# age_buckets = feature_column.bucketized_column(age, boundaries=[16, 22, 35, 55, 65])\n",
    "# feature_columns.append(age_buckets)\n",
    "# indicator_columns\n",
    "for col_name in ind_vars:\n",
    "    categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, X[col_name].unique())\n",
    "    indicator_column = feature_column.indicator_column(categorical_column)\n",
    "    feature_columns.append(indicator_column)\n",
    "# embedding columns\n",
    "for col_name in emb_vars:\n",
    "    emb_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, X[col_name].unique())\n",
    "    col_embedding = feature_column.embedding_column(emb_column, dimension=5)\n",
    "    feature_columns.append(col_embedding)\n",
    "\n",
    "# Convert all setup into new dataset\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "X = feature_layer(dict(X)).numpy()\n",
    "print('New shape of the input data set:',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EiMyeEfZvoJ",
    "outputId": "6dc67caf-d5a5-4514-e852-737a7b5c6000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (607907, 59)\n",
      "Validation features shape: (151977, 59)\n",
      "Test features shape: (189972, 59)\n"
     ]
    }
   ],
   "source": [
    "# %% Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=48)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=48)\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation features shape:', X_val.shape)\n",
    "print('Test features shape:', X_test.shape)\n",
    "\n",
    "# %% standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Metrics\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,accuracy_score\n",
    "\n",
    "# %% Function to compare the prediction and true labels\n",
    "def get_accs2(label, pred_proba, tr_time=0,index=None):\n",
    "    prediction = pred_proba.argmax(axis=1)\n",
    "    cm = confusion_matrix(label, prediction)\n",
    "    length = cm.shape[0]\n",
    "    num_cases = len(label)\n",
    "    # global accuracy\n",
    "    glb_acc = np.trace(cm) / len(label)\n",
    "    ind_accs = cm / np.sum(cm, axis=1)[:, np.newaxis]\n",
    "    accs = [ind_accs[i, i] for i in range(length)]\n",
    "    cols = ['Class {}'.format(i) for i in range(length)]\n",
    "    # Global accuracy\n",
    "    accs.append(glb_acc)\n",
    "    # AUC\n",
    "    accs.append(roc_auc_score(label, pred_proba,multi_class='ovr'))\n",
    "    # G-mean\n",
    "    accs.append(geometric_mean_score(label, prediction, correction=0.001))\n",
    "    # Average perf\n",
    "    accs.append(np.mean(accs[-3:]))\n",
    "    # Training time\n",
    "    accs.append(np.round(tr_time,3))\n",
    "    cols = cols + ['Accuracy','AUC','G-mean','Avg_Pfm','Training Time']\n",
    "\n",
    "    out = np.array(accs).reshape(1, len(accs))\n",
    "    return pd.DataFrame(out, columns=cols,index=[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = {'roc_auc':       tf.keras.metrics.AUC(name='roc_auc',curve='ROC'),\n",
    "               'pr_auc':       tf.keras.metrics.AUC(name='pr_auc',curve='PR')                    \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(metric):\n",
    "    MLP = Sequential([Dense(10,\n",
    "                           activation='relu',\n",
    "                           input_dim=X_train.shape[1]\n",
    "                           ),\n",
    "                      Dropout(0.5),\n",
    "                      Dense(5, activation='softmax')])\n",
    "    MLP.compile(optimizer='adam',\n",
    "                #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[metric]\n",
    "               )\n",
    "    return MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stops(metric_name):\n",
    "    es = EarlyStopping(monitor='val_'+ metric_name,\n",
    "                   verbose=1,\n",
    "                   patience=10,\n",
    "                   mode='max',\n",
    "                   restore_best_weights=True)\n",
    "    return es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hkgPBmo7Y37"
   },
   "source": [
    "# Normal Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jrwRmaph7V8X",
    "outputId": "980e4e2b-f5c0-4eb9-88c6-c73b06787105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROS\n",
      "Resampled dataset shape Counter({1: 507237, 0: 507237, 2: 507237, 4: 507237, 3: 507237})\n",
      "resampling time is 0.63 seconds\n",
      "Train on 2536185 samples, validate on 151977 samples\n",
      "Epoch 1/50\n",
      "2536185/2536185 [==============================] - 109s 43us/sample - loss: 1.4686 - roc_auc: 0.7237 - val_loss: 1.3828 - val_roc_auc: 0.8107\n",
      "Epoch 2/50\n",
      "2536185/2536185 [==============================] - 108s 43us/sample - loss: 1.4626 - roc_auc: 0.7240 - val_loss: 1.4005 - val_roc_auc: 0.7996\n",
      "Epoch 3/50\n",
      "2536185/2536185 [==============================] - 108s 43us/sample - loss: 1.4612 - roc_auc: 0.7229 - val_loss: 1.3867 - val_roc_auc: 0.8079\n",
      "Epoch 4/50\n",
      "2536185/2536185 [==============================] - 108s 43us/sample - loss: 1.4608 - roc_auc: 0.7223 - val_loss: 1.3935 - val_roc_auc: 0.8024\n",
      "Epoch 5/50\n",
      "2536185/2536185 [==============================] - 108s 43us/sample - loss: 1.4604 - roc_auc: 0.7216 - val_loss: 1.4009 - val_roc_auc: 0.8000\n",
      "Epoch 6/50\n",
      "2536185/2536185 [==============================] - 108s 43us/sample - loss: 1.4604 - roc_auc: 0.7208 - val_loss: 1.3885 - val_roc_auc: 0.8075\n",
      "Epoch 7/50\n",
      "2536185/2536185 [==============================] - 108s 43us/sample - loss: 1.4601 - roc_auc: 0.7211 - val_loss: 1.3824 - val_roc_auc: 0.8092\n",
      "Epoch 8/50\n",
      "2536185/2536185 [==============================] - 108s 43us/sample - loss: 1.4599 - roc_auc: 0.7210 - val_loss: 1.4012 - val_roc_auc: 0.8027\n",
      "Epoch 9/50\n",
      "2536185/2536185 [==============================] - 108s 42us/sample - loss: 1.4595 - roc_auc: 0.7209 - val_loss: 1.3981 - val_roc_auc: 0.8009\n",
      "Epoch 10/50\n",
      "2536185/2536185 [==============================] - 107s 42us/sample - loss: 1.4594 - roc_auc: 0.7202 - val_loss: 1.3887 - val_roc_auc: 0.8085\n",
      "Epoch 11/50\n",
      "2535296/2536185 [============================>.] - ETA: 0s - loss: 1.4596 - roc_auc: 0.7200Restoring model weights from the end of the best epoch.\n",
      "2536185/2536185 [==============================] - 107s 42us/sample - loss: 1.4596 - roc_auc: 0.7200 - val_loss: 1.4040 - val_roc_auc: 0.8006\n",
      "Epoch 00011: early stopping\n",
      "Train on 2536185 samples, validate on 151977 samples\n",
      "Epoch 1/50\n",
      "2536185/2536185 [==============================] - 114s 45us/sample - loss: 1.4685 - pr_auc: 0.4283 - val_loss: 1.3875 - val_pr_auc: 0.5604\n",
      "Epoch 2/50\n",
      "2536185/2536185 [==============================] - 113s 44us/sample - loss: 1.4619 - pr_auc: 0.4292 - val_loss: 1.3870 - val_pr_auc: 0.5452\n",
      "Epoch 3/50\n",
      "2536185/2536185 [==============================] - 113s 45us/sample - loss: 1.4605 - pr_auc: 0.4283 - val_loss: 1.4042 - val_pr_auc: 0.5093\n",
      "Epoch 4/50\n",
      "2536185/2536185 [==============================] - 113s 44us/sample - loss: 1.4601 - pr_auc: 0.4271 - val_loss: 1.3860 - val_pr_auc: 0.5334\n",
      "Epoch 5/50\n",
      "2536185/2536185 [==============================] - 113s 45us/sample - loss: 1.4600 - pr_auc: 0.4256 - val_loss: 1.3851 - val_pr_auc: 0.5365\n",
      "Epoch 6/50\n",
      "2536185/2536185 [==============================] - 113s 45us/sample - loss: 1.4595 - pr_auc: 0.4250 - val_loss: 1.3666 - val_pr_auc: 0.5583\n",
      "Epoch 7/50\n",
      "2536185/2536185 [==============================] - 113s 44us/sample - loss: 1.4598 - pr_auc: 0.4244 - val_loss: 1.3512 - val_pr_auc: 0.5711\n",
      "Epoch 8/50\n",
      "2536185/2536185 [==============================] - 113s 44us/sample - loss: 1.4591 - pr_auc: 0.4244 - val_loss: 1.3828 - val_pr_auc: 0.5286\n",
      "Epoch 9/50\n",
      "2536185/2536185 [==============================] - 113s 44us/sample - loss: 1.4588 - pr_auc: 0.4248 - val_loss: 1.3711 - val_pr_auc: 0.5438\n",
      "Epoch 10/50\n",
      "2536185/2536185 [==============================] - 113s 44us/sample - loss: 1.4592 - pr_auc: 0.4238 - val_loss: 1.3962 - val_pr_auc: 0.5080\n",
      "Epoch 11/50\n",
      "2536185/2536185 [==============================] - 112s 44us/sample - loss: 1.4587 - pr_auc: 0.4244 - val_loss: 1.3984 - val_pr_auc: 0.5144\n",
      "Epoch 12/50\n",
      "2536185/2536185 [==============================] - 112s 44us/sample - loss: 1.4587 - pr_auc: 0.4237 - val_loss: 1.3958 - val_pr_auc: 0.5102\n",
      "Epoch 13/50\n",
      "2536185/2536185 [==============================] - 112s 44us/sample - loss: 1.4587 - pr_auc: 0.4239 - val_loss: 1.3743 - val_pr_auc: 0.5391\n",
      "Epoch 14/50\n",
      "2536185/2536185 [==============================] - 112s 44us/sample - loss: 1.4589 - pr_auc: 0.4236 - val_loss: 1.3816 - val_pr_auc: 0.5232\n",
      "Epoch 15/50\n",
      "2536185/2536185 [==============================] - 111s 44us/sample - loss: 1.4584 - pr_auc: 0.4236 - val_loss: 1.3863 - val_pr_auc: 0.5207\n",
      "Epoch 16/50\n",
      "2536185/2536185 [==============================] - 111s 44us/sample - loss: 1.4581 - pr_auc: 0.4238 - val_loss: 1.3919 - val_pr_auc: 0.5152\n",
      "Epoch 17/50\n",
      "2535360/2536185 [============================>.] - ETA: 0s - loss: 1.4584 - pr_auc: 0.4232Restoring model weights from the end of the best epoch.\n",
      "2536185/2536185 [==============================] - 112s 44us/sample - loss: 1.4584 - pr_auc: 0.4232 - val_loss: 1.3849 - val_pr_auc: 0.5251\n",
      "Epoch 00017: early stopping\n",
      "                 Accuracy       AUC    G-mean   Avg_Pfm  Training Time  \\\n",
      "MLP-ROS-roc_auc  0.489235  0.705258  0.376555  0.523683       1187.021   \n",
      "MLP-ROS-pr_auc   0.523830  0.697291  0.391587  0.537569       1912.713   \n",
      "\n",
      "                 Res_time  \n",
      "MLP-ROS-roc_auc  0.627185  \n",
      "MLP-ROS-pr_auc   0.627185  \n"
     ]
    }
   ],
   "source": [
    "Resamples = {'ROS':             RandomOverSampler(), \n",
    "             }\n",
    "rsts = pd.DataFrame()\n",
    "for key,value in Resamples.items():\n",
    "    start = time.time()\n",
    "    X_res, y_res = value.fit_resample(X_train, y_train)\n",
    "    end = time.time()\n",
    "    res_time = end - start\n",
    "    print(key)\n",
    "    print('Resampled dataset shape %s' % Counter(y_res))\n",
    "    print('resampling time is {0:.2f} seconds'.format(res_time))\n",
    "    for name, metric in early_stop.items():\n",
    "        model = create_mlp(metric)\n",
    "        start = time.time()\n",
    "        monitor = model.fit(X_res, pd.get_dummies(y_res).values,\n",
    "                        callbacks=[early_stops(name)],\n",
    "                        validation_data=(X_val, pd.get_dummies(y_val).values),\n",
    "                        verbose=1, epochs = EPOCH)\n",
    "        end = time.time()\n",
    "        # use the model to make predictions with the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "        # get the evaluation metrics\n",
    "        result = get_accs2(y_test.values, y_pred, end-start,'MLP-'+key+'-'+name)\n",
    "        result['Res_time'] = res_time\n",
    "        rsts = rsts.append(result)\n",
    "rsts.to_csv('MLP_AUC_RES '+time.ctime()+'.csv')\n",
    "print(rsts.iloc[:,5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rleqZyMvVQ4e"
   },
   "source": [
    "# Hybrid Resampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebtofqp5Xo21",
    "outputId": "20a0a829-0c4d-428e-82c9-ed787e9852e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 65541, 0: 507237, 2: 28954, 4: 1086, 3: 5089})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dict = Counter(y_train)\n",
    "y_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-dAKpcXyy3w"
   },
   "source": [
    "## Oversampling and then undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uTMR48M-b-xZ"
   },
   "outputs": [],
   "source": [
    "ss = {}\n",
    "for i in range(2,5):\n",
    "    ss[i] = y_dict[1]\n",
    "oses = ['ROS','SMOTE']\n",
    "uses = ['RUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "te2eBMF3hRVt",
    "outputId": "5dc2cfcf-c394-4746-df42-dce317a21762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROS-RUS\n",
      "Resampled dataset shape Counter({0: 65541, 1: 65541, 2: 65541, 3: 65541, 4: 65541})\n",
      "Resamling time 68.18 sec\n",
      "Train on 327705 samples, validate on 151977 samples\n",
      "Epoch 1/50\n",
      "326848/327705 [============================>.] - ETA: 0s - loss: 1.4793 - roc_auc: 0.7167WARNING:tensorflow:Early stopping conditioned on metric `val_roc_auc` which is not available. Available metrics are: loss,roc_auc\n",
      "327705/327705 [==============================] - 19s 57us/sample - loss: 1.4793 - roc_auc: 0.7168\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0d7e65c63285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                             verbose=1, epochs = EPOCH)\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# use the model to make predictions with the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m    397\u001b[0m                                  prefix='val_')\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0mcurrent_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     with training_context.on_batch(\n\u001b[0;32m--> 126\u001b[0;31m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0m\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, step, mode, size)\u001b[0m\n\u001b[1;32m    779\u001b[0m       \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m       self.callbacks._call_batch_hook(\n\u001b[0;32m--> 781\u001b[0;31m           mode, 'begin', step, batch_logs)\n\u001b[0m\u001b[1;32m    782\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     if (self._delta_t_batch > 0. and\n\u001b[1;32m    244\u001b[0m         delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3493\u001b[0m     \"\"\"\n\u001b[1;32m   3494\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3495\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3497\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3401\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3403\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3404\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3526\u001b[0m             \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m         \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpartition\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/project/cacds/apps/easybuild/software/Anaconda3/5.0.1/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;31m# flatten returns (1, N) for np.matrix, so always use the last axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for os_name in oses:\n",
    "    for us_name in uses:\n",
    "        key = os_name + '-'+us_name\n",
    "        print(key)\n",
    "        if us_name == 'ROS': \n",
    "            res = RandomOverSampler(sampling_strategy=ss)\n",
    "        else: res = SMOTE(sampling_strategy=ss)\n",
    "        start = time.time()\n",
    "        X_res, y_res = res.fit_resample(X_train, y_train)\n",
    "\n",
    "        if us_name == 'RUS': \n",
    "            res = RandomUnderSampler(sampling_strategy='majority')\n",
    "        else: res = NearMiss(sampling_strategy='majority')  \n",
    "        X_res, y_res = res.fit_resample(X_res, y_res)\n",
    "        end = time.time()\n",
    "        res_time = end-start\n",
    "\n",
    "        print('Resampled dataset shape %s' % Counter(y_res))\n",
    "        print('Resamling time %.2f sec' % (res_time))\n",
    "        for name, metric in early_stop.items():\n",
    "            model = create_mlp(metric)\n",
    "            start = time.time()\n",
    "            monitor = model.fit(X_res, pd.get_dummies(y_res).values,\n",
    "                            callbacks=[early_stops(name)],\n",
    "                            validation_data=(X_val, pd.get_dummies(y_val).values),\n",
    "                            verbose=1, epochs = EPOCH)\n",
    "            end = time.time()\n",
    "            # use the model to make predictions with the test data\n",
    "            y_pred = model.predict(X_test)\n",
    "            # get the evaluation metrics\n",
    "            result = get_accs2(y_test.values, y_pred, end-start,'MLP-'+key+'-'+name)\n",
    "            result['Res_time'] = res_time\n",
    "            rsts = rsts.append(result)\n",
    "rsts.to_csv('MLP_AUC_RES '+time.ctime()+'.csv')\n",
    "print(rsts.iloc[:,5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwgGM78Bysq5"
   },
   "source": [
    "## Under sampling and then over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oses = ['ROS','SMOTE']\n",
    "uses = ['RUS','NearMiss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "3bilJdcJzW-J",
    "outputId": "427368a2-12ef-4c39-f94e-4d206ddbc40d"
   },
   "outputs": [],
   "source": [
    "for us_name in uses:\n",
    "    for os_name in oses:\n",
    "        key = us_name + '2'+os_name\n",
    "        print(key)\n",
    "        if us_name == 'RUS': \n",
    "            res = RandomUnderSampler(sampling_strategy={0: y_dict[1]})\n",
    "        else: res = NearMiss(sampling_strategy={0: y_dict[1]})\n",
    "        start = time.time()\n",
    "        X_res, y_res = res.fit_resample(X_train, y_train)\n",
    "\n",
    "        if us_name == 'ROS': \n",
    "            res = RandomOverSampler(sampling_strategy='not majority')\n",
    "        else: res = SMOTE(sampling_strategy='not majority')\n",
    "        X_res, y_res = res.fit_resample(X_res, y_res)\n",
    "        end = time.time()\n",
    "        res_time = end-start\n",
    "        print('Resampled dataset shape %s' % Counter(y_res))\n",
    "        print('Resamling time %.2f sec' % (res_time))\n",
    "        for name, metric in early_stop.items():\n",
    "            model = create_mlp(metric)\n",
    "            start = time.time()\n",
    "            monitor = model.fit(X_res, pd.get_dummies(y_res).values,\n",
    "                            callbacks=[early_stops(name)],\n",
    "                            validation_data=(X_val, pd.get_dummies(y_val).values),\n",
    "                            verbose=1, epochs = EPOCH)\n",
    "            end = time.time()\n",
    "            # use the model to make predictions with the test data\n",
    "            y_pred = model.predict(X_test)\n",
    "            # get the evaluation metrics\n",
    "            result = get_accs2(y_test.values, y_pred, end-start,'MLP-'+key+'-'+name)\n",
    "            result['Res_time'] = res_time\n",
    "            rsts = rsts.append(result)\n",
    "rsts.to_csv('MLP_AUC_RES '+time.ctime()+'.csv')\n",
    "print(rsts.iloc[:,5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsts.to_csv('MLP_AUC_RES '+time.ctime()+'.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "VCA_2.1_MLP_resampling.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
